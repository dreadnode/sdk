# GRPO Training Configuration for Math Problem Solving
# Usage: dn.train("examples/configs/grpo_math.yaml")

trainer: grpo

# Model Configuration
model_name: Qwen/Qwen2.5-0.5B-Instruct

# Training Parameters
max_steps: 100
num_prompts_per_step: 4
num_generations_per_prompt: 4
learning_rate: 1.0e-6
temperature: 0.7
max_new_tokens: 256

# Logging
log_interval: 10
checkpoint_interval: 50

# Dataset Configuration
# Supports: dreadnode, huggingface, jsonl, list
dataset:
  type: huggingface  # or "dreadnode" to use dn.load("my-dataset")
  name: openai/gsm8k
  config: main
  split: train
  max_samples: 500
  prompt_field: question
  prompt_template: |
    Solve this math problem step by step.

    Problem: {question}

    Show your work and provide the final answer.

# Reward Configuration
# Built-in types: correctness, length, contains
# Or use scorers= argument with dn.scorer functions
reward:
  type: contains
  required:
    - "answer"
    - "="
  reward_per_match: 0.5

# Alternative: Use dreadnode dataset
# dataset:
#   type: dreadnode
#   name: my-math-dataset
#   prompt_field: question
#   max_samples: 1000

# Alternative: Use with scorers (in Python)
# result = dn.train(
#     "config.yaml",
#     scorers=[my_correctness_scorer, my_format_scorer]
# )
