---
title: dreadnode.api
---

{/*
::: dreadnode.api.client
::: dreadnode.api.models
*/}

ApiClient
---------

```python
ApiClient(
    base_url: str,
    *,
    api_key: str | None = None,
    cookies: dict[str, str] | None = None,
    debug: bool = False,
    timeout: int = 30,
)
```

Client for the Dreadnode API.

This class provides methods to interact with the Dreadnode API, including
retrieving projects, runs, tasks, and exporting data.

Initializes the API client.

**Parameters:**

* **`base_url`**
  (`str`)
  –The base URL of the Dreadnode API.
* **`api_key`**
  (`str | None`, default:
  `None`
  )
  –The API key for authentication.
* **`cookies`**
  (`dict[str, str] | None`, default:
  `None`
  )
  –A dictionary of cookies to include in requests.
* **`debug`**
  (`bool`, default:
  `False`
  )
  –Whether to enable debug logging. Defaults to False.
* **`timeout`**
  (`int`, default:
  `30`
  )
  –The timeout for HTTP requests in seconds.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def __init__(
    self,
    base_url: str,
    *,
    api_key: str | None = None,
    cookies: dict[str, str] | None = None,
    debug: bool = False,
    timeout: int = 30,
):
    """
    Initializes the API client.

    Args:
        base_url: The base URL of the Dreadnode API.
        api_key: The API key for authentication.
        cookies: A dictionary of cookies to include in requests.
        debug: Whether to enable debug logging. Defaults to False.
        timeout: The timeout for HTTP requests in seconds.
    """
    self._base_url = base_url.rstrip("/")
    if not self._base_url.endswith("/api"):
        self._base_url += "/api"

    _cookies = httpx.Cookies()
    cookie_domain = urlparse(base_url).hostname
    if cookie_domain is None:
        raise ValueError(f"Invalid URL: {base_url}")

    if cookie_domain == "localhost":
        cookie_domain = "localhost.local"

    for key, value in (cookies or {}).items():
        _cookies.set(key, value, domain=cookie_domain)

    headers = {
        "User-Agent": f"dreadnode-sdk/{VERSION}",
        "Accept": "application/json",
    }

    if api_key:
        headers["X-API-Key"] = api_key

    self._client = httpx.Client(
        headers=headers,
        base_url=self._base_url,
        timeout=httpx.Timeout(timeout, connect=5),
        cookies=_cookies,
    )

    if debug:
        self._client.event_hooks["request"].append(self._log_request)
        self._client.event_hooks["response"].append(self._log_response)
```


</Accordion>

### create\_dataset

```python
create_dataset(
    request: CreateDatasetRequest,
) -> CreateDatasetResponse
```

Creates a new dataset.

**Parameters:**

* **`request`**
  (`DatasetUploadRequest`)
  –The dataset upload request object.

**Returns:**

* **`DatasetUploadResponse`** ( `CreateDatasetResponse`
  ) –The dataset upload response object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def create_dataset(
    self,
    request: CreateDatasetRequest,
) -> CreateDatasetResponse:
    """
    Creates a new dataset.

    Args:
        request (DatasetUploadRequest): The dataset upload request object.

    Returns:
        DatasetUploadResponse: The dataset upload response object.
    """

    response = self.request("POST", "/datasets", json_data=request.model_dump())

    return CreateDatasetResponse(**response.json())
```


</Accordion>

### create\_project

```python
create_project(
    name: str,
    key: str,
    workspace_id: UUID | None = None,
    organization_id: UUID | None = None,
) -> Project
```

Creates a new project.

**Parameters:**

* **`name`**
  (`str`)
  –The name of the project. If None, a default name will be used.
* **`workspace_id`**
  (`UUID | None`, default:
  `None`
  )
  –The workspace ID to create the project in. If None, the default workspace will be used.
* **`organization_id`**
  (`UUID | None`, default:
  `None`
  )
  –The organization ID to create the project in. If None, the default organization will be used.

**Returns:**

* **`Project`** ( `Project`
  ) –The created Project object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def create_project(
    self,
    name: str,
    key: str,
    workspace_id: UUID | None = None,
    organization_id: UUID | None = None,
) -> Project:
    """Creates a new project.

    Args:
        name: The name of the project. If None, a default name will be used.
        workspace_id: The workspace ID to create the project in. If None, the default workspace will be used.
        organization_id: The organization ID to create the project in. If None, the default organization will be used.

    Returns:
        Project: The created Project object.
    """
    payload: dict[str, t.Any] = {}
    payload["name"] = name
    payload["key"] = key
    if workspace_id is not None:
        payload["workspace_id"] = str(workspace_id)
    if organization_id is not None:
        payload["org_id"] = str(organization_id)

    response = self.request("POST", "/strikes/projects", json_data=payload)
    return Project(**response.json())
```


</Accordion>

### create\_workspace

```python
create_workspace(
    name: str,
    key: str,
    organization_id: UUID,
    description: str | None = None,
) -> Workspace
```

Creates a new workspace.

**Parameters:**

* **`name`**
  (`str`)
  –The name of the workspace.
* **`organization_id`**
  (`str | UUID`)
  –The organization ID to create the workspace in.

**Returns:**

* **`Workspace`** ( `Workspace`
  ) –The created Workspace object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def create_workspace(
    self,
    name: str,
    key: str,
    organization_id: UUID,
    description: str | None = None,
) -> Workspace:
    """
    Creates a new workspace.

    Args:
        name (str): The name of the workspace.
        organization_id (str | UUID): The organization ID to create the workspace in.

    Returns:
        Workspace: The created Workspace object.
    """

    payload = {
        "name": name,
        "key": key,
        "description": description,
        "org_id": str(organization_id),
    }

    response = self.request("POST", "/workspaces", json_data=payload)
    return Workspace(**response.json())
```


</Accordion>

### delete\_dataset

```python
delete_dataset(dataset_id_or_key: str | UUID) -> None
```

Deletes a specific dataset.

**Parameters:**

* **`dataset_id_or_key`**
  (`str | UUID`)
  –The dataset identifier.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def delete_dataset(self, dataset_id_or_key: str | UUID) -> None:
    """
    Deletes a specific dataset.

    Args:
        dataset_id_or_key (str | UUID): The dataset identifier.
    """

    self.request("DELETE", f"/datasets/{dataset_id_or_key}")
```


</Accordion>

### delete\_workspace

```python
delete_workspace(workspace_id: str | UUID) -> None
```

Deletes a specific workspace.

**Parameters:**

* **`workspace_id`**
  (`str | UUID`)
  –The workspace key.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def delete_workspace(self, workspace_id: str | UUID) -> None:
    """
    Deletes a specific workspace.

    Args:
        workspace_id (str | UUID): The workspace key.
    """

    self.request("DELETE", f"/workspaces/{workspace_id!s}")
```


</Accordion>

### download\_dataset

```python
download_dataset(
    request: DatasetDownloadRequest,
) -> UserDataCredentials
```

Downloads the dataset content.

**Parameters:**

* **`request`**
  (`DatasetDownloadRequest`)
  –The dataset download request object.

**Returns:**

* **`bytes`** ( `UserDataCredentials`
  ) –The dataset content as bytes.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def download_dataset(self, request: DatasetDownloadRequest) -> UserDataCredentials:
    """
    Downloads the dataset content.

    Args:
        request (DatasetDownloadRequest): The dataset download request object.

    Returns:
        bytes: The dataset content as bytes.
    """
    response = self.request(
        "GET",
        f"/datasets/{request.dataset_uri}/credentials",
        params={
            "version": request.version,
        },
    )

    return UserDataCredentials(**response.json())
```


</Accordion>

### export\_metrics

```python
export_metrics(
    project: str,
    *,
    filter: str | None = None,
    status: StatusFilter = "completed",
    metrics: list[str] | None = None,
    aggregations: list[MetricAggregationType] | None = None,
) -> pd.DataFrame
```

Exports metric data for a specific project.

**Parameters:**

* **`project`**
  (`str`)
  –The project identifier.
* **`filter`**
  (`str | None`, default:
  `None`
  )
  –A filter to apply to the exported data. Defaults to None.
* **`status`**
  (`StatusFilter`, default:
  `'completed'`
  )
  –The status of metrics to include. Defaults to "completed".
* **`metrics`**
  (`list[str] | None`, default:
  `None`
  )
  –A list of metric names to include. Defaults to None.
* **`aggregations`**
  (`list[MetricAggregationType] | None`, default:
  `None`
  )
  –A list of aggregation types to apply. Defaults to None.

**Returns:**

* `DataFrame`
  –A DataFrame containing the exported metric data.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def export_metrics(
    self,
    project: str,
    *,
    filter: str | None = None,
    # format: ExportFormat = "parquet",
    status: StatusFilter = "completed",
    metrics: list[str] | None = None,
    aggregations: list[MetricAggregationType] | None = None,
) -> "pd.DataFrame":
    """
    Exports metric data for a specific project.

    Args:
        project: The project identifier.
        filter: A filter to apply to the exported data. Defaults to None.
        status: The status of metrics to include. Defaults to "completed".
        metrics: A list of metric names to include. Defaults to None.
        aggregations: A list of aggregation types to apply. Defaults to None.

    Returns:
        A DataFrame containing the exported metric data.
    """
    import pandas as pd

    response = self.request(
        "GET",
        f"/strikes/projects/{project!s}/export/metrics",
        params={
            "format": "parquet",
            "status": status,
            "filter": filter,
            **({"metrics": metrics} if metrics else {}),
            **({"aggregations": aggregations} if aggregations else {}),
        },
    )
    return pd.read_parquet(io.BytesIO(response.content))
```


</Accordion>

### export\_parameters

```python
export_parameters(
    project: str,
    *,
    filter: str | None = None,
    status: StatusFilter = "completed",
    parameters: list[str] | None = None,
    metrics: list[str] | None = None,
    aggregations: list[MetricAggregationType] | None = None,
) -> pd.DataFrame
```

Exports parameter data for a specific project.

**Parameters:**

* **`project`**
  (`str`)
  –The project identifier.
* **`filter`**
  (`str | None`, default:
  `None`
  )
  –A filter to apply to the exported data. Defaults to None.
* **`status`**
  (`StatusFilter`, default:
  `'completed'`
  )
  –The status of parameters to include. Defaults to "completed".
* **`parameters`**
  (`list[str] | None`, default:
  `None`
  )
  –A list of parameter names to include. Defaults to None.
* **`metrics`**
  (`list[str] | None`, default:
  `None`
  )
  –A list of metric names to include. Defaults to None.
* **`aggregations`**
  (`list[MetricAggregationType] | None`, default:
  `None`
  )
  –A list of aggregation types to apply. Defaults to None.

**Returns:**

* `DataFrame`
  –A DataFrame containing the exported parameter data.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def export_parameters(
    self,
    project: str,
    *,
    filter: str | None = None,
    # format: ExportFormat = "parquet",
    status: StatusFilter = "completed",
    parameters: list[str] | None = None,
    metrics: list[str] | None = None,
    aggregations: list[MetricAggregationType] | None = None,
) -> "pd.DataFrame":
    """
    Exports parameter data for a specific project.

    Args:
        project: The project identifier.
        filter: A filter to apply to the exported data. Defaults to None.
        status: The status of parameters to include. Defaults to "completed".
        parameters: A list of parameter names to include. Defaults to None.
        metrics: A list of metric names to include. Defaults to None.
        aggregations: A list of aggregation types to apply. Defaults to None.

    Returns:
        A DataFrame containing the exported parameter data.
    """
    import pandas as pd

    response = self.request(
        "GET",
        f"/strikes/projects/{project!s}/export/parameters",
        params={
            "format": "parquet",
            "status": status,
            "filter": filter,
            **({"parameters": parameters} if parameters else {}),
            **({"metrics": metrics} if metrics else {}),
            **({"aggregations": aggregations} if aggregations else {}),
        },
    )
    return pd.read_parquet(io.BytesIO(response.content))
```


</Accordion>

### export\_runs

```python
export_runs(
    project: str,
    *,
    filter: str | None = None,
    status: StatusFilter = "completed",
    aggregations: list[MetricAggregationType] | None = None,
    format: ExportFormat = "parquet",
    base_dir: str | None = None,
) -> str
```

Export runs using pagination - always writes to disk.

**Parameters:**

* **`project`**
  (`str`)
  –The project identifier
* **`filter`**
  (`str | None`, default:
  `None`
  )
  –A filter to apply to the exported data
* **`status`**
  (`StatusFilter`, default:
  `'completed'`
  )
  –The status of runs to include
* **`aggregations`**
  (`list[MetricAggregationType] | None`, default:
  `None`
  )
  –A list of aggregation types to apply
* **`format`**
  (`ExportFormat`, default:
  `'parquet'`
  )
  –Output format - "parquet", "csv", "json", "jsonl"
* **`base_dir`**
  (`str | None`, default:
  `None`
  )
  –Base directory for export (defaults to "./strikes-data")

**Returns:**

* **`str`** ( `str`
  ) –Path to the export directory

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def export_runs(
    self,
    project: str,
    *,
    filter: str | None = None,
    status: StatusFilter = "completed",
    aggregations: list[MetricAggregationType] | None = None,
    format: ExportFormat = "parquet",
    base_dir: str | None = None,
) -> str:
    """
    Export runs using pagination - always writes to disk.

    Args:
        project: The project identifier
        filter: A filter to apply to the exported data
        status: The status of runs to include
        aggregations: A list of aggregation types to apply
        format: Output format - "parquet", "csv", "json", "jsonl"
        base_dir: Base directory for export (defaults to "./strikes-data")

    Returns:
        str: Path to the export directory
    """
    import pandas as pd

    logger.info(f"Starting paginated export for project '{project}', format='{format}'")

    page = 1
    first_response = self.request(
        "GET",
        f"/strikes/projects/{project!s}/export/paginated",
        params={
            "page": page,
            "status": status,
            **({"filter": filter} if filter else {}),
            **({"aggregations": aggregations} if aggregations else {}),
        },
    )

    if not first_response.content:
        logger.info("No data found")

    first_chunk = pd.read_parquet(io.BytesIO(first_response.content))

    total_runs = int(first_response.headers.get("x-total", "0"))
    has_more = first_response.headers.get("x-has-more", "false") == "true"

    logger.info(f"Total runs: {total_runs}, Has more: {has_more}")

    logger.info(f"Writing {total_runs} runs to disk")
    return self._export_to_disk(
        project,
        first_chunk,
        dict(first_response.headers),
        filter,
        status,
        aggregations,
        format,
        str(base_dir) if base_dir else None,
    )
```


</Accordion>

### export\_timeseries

```python
export_timeseries(
    project: str,
    *,
    filter: str | None = None,
    status: StatusFilter = "completed",
    metrics: list[str] | None = None,
    time_axis: TimeAxisType = "relative",
    aggregations: list[TimeAggregationType] | None = None,
) -> pd.DataFrame
```

Exports timeseries data for a specific project.

**Parameters:**

* **`project`**
  (`str`)
  –The project identifier.
* **`filter`**
  (`str | None`, default:
  `None`
  )
  –A filter to apply to the exported data. Defaults to None.
* **`status`**
  (`StatusFilter`, default:
  `'completed'`
  )
  –The status of timeseries to include. Defaults to "completed".
* **`metrics`**
  (`list[str] | None`, default:
  `None`
  )
  –A list of metric names to include. Defaults to None.
* **`time_axis`**
  (`TimeAxisType`, default:
  `'relative'`
  )
  –The type of time axis to use. Defaults to "relative".
* **`aggregations`**
  (`list[TimeAggregationType] | None`, default:
  `None`
  )
  –A list of aggregation types to apply. Defaults to None.

**Returns:**

* `DataFrame`
  –A DataFrame containing the exported timeseries data.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def export_timeseries(
    self,
    project: str,
    *,
    filter: str | None = None,
    # format: ExportFormat = "parquet",
    status: StatusFilter = "completed",
    metrics: list[str] | None = None,
    time_axis: TimeAxisType = "relative",
    aggregations: list[TimeAggregationType] | None = None,
) -> "pd.DataFrame":
    """
    Exports timeseries data for a specific project.

    Args:
        project: The project identifier.
        filter: A filter to apply to the exported data. Defaults to None.
        status: The status of timeseries to include. Defaults to "completed".
        metrics: A list of metric names to include. Defaults to None.
        time_axis: The type of time axis to use. Defaults to "relative".
        aggregations: A list of aggregation types to apply. Defaults to None.

    Returns:
        A DataFrame containing the exported timeseries data.
    """
    import pandas as pd

    response = self.request(
        "GET",
        f"/strikes/projects/{project!s}/export/timeseries",
        params={
            "format": "parquet",
            "status": status,
            "filter": filter,
            "time_axis": time_axis,
            **({"metrics": metrics} if metrics else {}),
            **({"aggregation": aggregations} if aggregations else {}),
        },
    )
    return pd.read_parquet(io.BytesIO(response.content))
```


</Accordion>

### get\_dataset

```python
get_dataset(
    dataset_id_or_key: str | UUID,
) -> DatasetMetadata
```

Retrieves details of a specific dataset.

**Parameters:**

* **`dataset_id_or_key`**
  (`str | UUID`)
  –The dataset identifier.

**Returns:**

* **`DatasetMetadata`** ( `DatasetMetadata`
  ) –The DatasetMetadata object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_dataset(
    self,
    dataset_id_or_key: str | UUID,
) -> DatasetMetadata:
    """
    Retrieves details of a specific dataset.

    Args:
        dataset_id_or_key (str | UUID): The dataset identifier.

    Returns:
        DatasetMetadata: The DatasetMetadata object.
    """
    response = self.request("GET", f"/datasets/{dataset_id_or_key}")
    return DatasetMetadata(**response.json())
```


</Accordion>

### get\_dataset\_access\_credentials

```python
get_dataset_access_credentials(
    dataset_id: UUID, version: str
) -> UserDataCredentials
```

Retrieves dataset access credentials for a specific dataset.

**Parameters:**

* **`dataset_id`**
  (`UUID`)
  –The dataset identifier.

Returns:
The user data credentials object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_dataset_access_credentials(
    self,
    dataset_id: UUID,
    version: str,
) -> UserDataCredentials:
    """
    Retrieves dataset access credentials for a specific dataset.

    Args:
        dataset_id (UUID): The dataset identifier.
    Returns:
        The user data credentials object.
    """
    params: dict[str, str] = {"version": version}
    response = self.request("GET", f"/datasets/{dataset_id!s}/credentials", params=params)
    return UserDataCredentials(**response.json())
```


</Accordion>

### get\_device\_codes

```python
get_device_codes() -> DeviceCodeResponse
```

Start the authentication flow by requesting user and device codes.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_device_codes(self) -> DeviceCodeResponse:
    """Start the authentication flow by requesting user and device codes."""

    response = self.request("POST", "/auth/device/code")
    return DeviceCodeResponse(**response.json())
```


</Accordion>

### get\_github\_access\_token

```python
get_github_access_token(
    repos: list[str],
) -> GithubTokenResponse
```

Try to get a GitHub access token for the given repositories.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_github_access_token(self, repos: list[str]) -> GithubTokenResponse:
    """Try to get a GitHub access token for the given repositories."""
    response = self.request("POST", "/github/token", json_data={"repos": repos})
    return GithubTokenResponse(**response.json())
```


</Accordion>

### get\_organization

```python
get_organization(org_id_or_key: UUID | str) -> Organization
```

Retrieves details of a specific organization.

**Parameters:**

* **`org_id_or_key`**
  (`str | UUID`)
  –The organization identifier.

**Returns:**

* **`Organization`** ( `Organization`
  ) –The Organization object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_organization(self, org_id_or_key: UUID | str) -> Organization:
    """
    Retrieves details of a specific organization.

    Args:
        org_id_or_key (str | UUID): The organization identifier.

    Returns:
        Organization: The Organization object.
    """
    response = self.request("GET", f"/organizations/{org_id_or_key!s}")
    return Organization(**response.json())
```


</Accordion>

### get\_platform\_registry\_credentials

```python
get_platform_registry_credentials() -> (
    ContainerRegistryCredentials
)
```

Retrieves container registry credentials for Docker image access.

**Returns:**

* `ContainerRegistryCredentials`
  –The container registry credentials object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_platform_registry_credentials(self) -> ContainerRegistryCredentials:
    """
    Retrieves container registry credentials for Docker image access.

    Returns:
        The container registry credentials object.
    """
    response = self.request("POST", "/platform/registry-token")
    return ContainerRegistryCredentials(**response.json())
```


</Accordion>

### get\_platform\_releases

```python
get_platform_releases(
    tag: str, services: list[str]
) -> RegistryImageDetails
```

Resolves the platform releases for the current project.

**Returns:**

* `RegistryImageDetails`
  –The resolved platform releases as a ResolveReleasesResponse object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_platform_releases(self, tag: str, services: list[str]) -> RegistryImageDetails:
    """
    Resolves the platform releases for the current project.

    Returns:
        The resolved platform releases as a ResolveReleasesResponse object.
    """
    from dreadnode.version import VERSION

    payload = {"tag": tag, "services": services, "cli_version": VERSION}
    response = self.request("POST", "/platform/get-releases", json_data=payload)
    return RegistryImageDetails(**response.json())
```


</Accordion>

### get\_platform\_templates

```python
get_platform_templates(tag: str) -> bytes
```

Retrieves the available platform templates.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_platform_templates(self, tag: str) -> bytes:
    """
    Retrieves the available platform templates.
    """
    params = {"tag": tag}
    response = self.request("GET", "/platform/templates/all", params=params)
    zip_content: bytes = response.content
    return zip_content
```


</Accordion>

### get\_project

```python
get_project(
    project_identifier: str | UUID, workspace_id: UUID
) -> Project
```

Retrieves details of a specific project.

**Parameters:**

* **`project_identifier`**
  (`str | UUID`)
  –The project identifier. ID or key.

**Returns:**

* **`Project`** ( `Project`
  ) –The Project object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_project(self, project_identifier: str | UUID, workspace_id: UUID) -> Project:
    """Retrieves details of a specific project.

    Args:
        project_identifier (str | UUID): The project identifier. ID or key.

    Returns:
        Project: The Project object.
    """
    response = self.request(
        "GET",
        f"/strikes/projects/{project_identifier!s}",
        params={"workspace_id": workspace_id},
    )
    return Project(**response.json())
```


</Accordion>

### get\_run

```python
get_run(run: str | ULID) -> Run
```

Retrieves details of a specific run.

**Parameters:**

* **`run`**
  (`str | ULID`)
  –The run identifier.

**Returns:**

* `Run`
  –The Run object containing details of the run.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_run(self, run: str | ULID) -> Run:
    """
    Retrieves details of a specific run.

    Args:
        run: The run identifier.

    Returns:
        The Run object containing details of the run.
    """
    return process_run(self._get_run(run))
```


</Accordion>

### get\_run\_tasks

```python
get_run_tasks(
    run: str | ULID, *, format: Literal["tree"]
) -> list[TaskTree]
```

```python
get_run_tasks(
    run: str | ULID, *, format: Literal["flat"] = "flat"
) -> list[Task]
```

```python
get_run_tasks(
    run: str | ULID, *, format: TraceFormat = "flat"
) -> list[Task] | list[TaskTree]
```

Gets all tasks for a specific run.

**Parameters:**

* **`run`**
  (`str | ULID`)
  –The run identifier.
* **`format`**
  (`TraceFormat`, default:
  `'flat'`
  )
  –The format of the tasks to return. Can be "flat" or "tree".

**Returns:**

* `list[Task] | list[TaskTree]`
  –A list of Task objects in flat format or a list of TaskTree objects in tree format.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_run_tasks(
    self, run: str | ULID, *, format: TraceFormat = "flat"
) -> list[Task] | list[TaskTree]:
    """
    Gets all tasks for a specific run.

    Args:
        run: The run identifier.
        format: The format of the tasks to return. Can be "flat" or "tree".

    Returns:
        A list of Task objects in flat format or a list of TaskTree objects in tree format.
    """
    raw_run = self._get_run(run)
    response = self.request("GET", f"/strikes/projects/runs/{run!s}/tasks/full")
    raw_tasks = [RawTask(**task) for task in response.json()]
    tasks = [process_task(task, raw_run) for task in raw_tasks]
    tasks = sorted(tasks, key=lambda x: x.timestamp)
    return tasks if format == "flat" else convert_flat_tasks_to_tree(tasks)
```


</Accordion>

### get\_run\_trace

```python
get_run_trace(
    run: str | ULID, *, format: Literal["tree"]
) -> list[TraceTree]
```

```python
get_run_trace(
    run: str | ULID, *, format: Literal["flat"] = "flat"
) -> list[Task | TraceSpan]
```

```python
get_run_trace(
    run: str | ULID, *, format: TraceFormat = "flat"
) -> list[Task | TraceSpan] | list[TraceTree]
```

Retrieves the run trace (spans+tasks) of a specific run.

**Parameters:**

* **`run`**
  (`str | ULID`)
  –The run identifier.
* **`format`**
  (`TraceFormat`, default:
  `'flat'`
  )
  –The format of the trace to return. Can be "flat" or "tree".

**Returns:**

* `list[Task | TraceSpan] | list[TraceTree]`
  –A list of Task or TraceSpan objects in flat format or a list of TraceTree objects in tree format.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_run_trace(
    self, run: str | ULID, *, format: TraceFormat = "flat"
) -> list[Task | TraceSpan] | list[TraceTree]:
    """
    Retrieves the run trace (spans+tasks) of a specific run.

    Args:
        run: The run identifier.
        format: The format of the trace to return. Can be "flat" or "tree".

    Returns:
        A list of Task or TraceSpan objects in flat format or a list of TraceTree objects in tree format.
    """
    raw_run = self._get_run(run)
    response = self.request("GET", f"/strikes/projects/runs/{run!s}/spans/full")
    trace: list[Task | TraceSpan] = []
    for item in response.json():
        if "parent_task_span_id" in item:
            trace.append(process_task(RawTask(**item), raw_run))
        else:
            trace.append(TraceSpan(**item))

    trace = sorted(trace, key=lambda x: x.timestamp)
    return trace if format == "flat" else convert_flat_trace_to_tree(trace)
```


</Accordion>

### get\_user

```python
get_user() -> UserResponse
```

Get the user email and username.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_user(self) -> UserResponse:
    """Get the user email and username."""

    response = self.request("GET", "/user")
    return UserResponse(**response.json())
```


</Accordion>

### get\_workspace

```python
get_workspace(
    workspace_id_or_key: UUID | str,
    org_id: UUID | None = None,
) -> Workspace
```

Retrieves details of a specific workspace.

**Parameters:**

* **`workspace_id_or_key`**
  (`str | UUID`)
  –The workspace identifier.

**Returns:**

* **`Workspace`** ( `Workspace`
  ) –The Workspace object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_workspace(
    self, workspace_id_or_key: UUID | str, org_id: UUID | None = None
) -> Workspace:
    """
    Retrieves details of a specific workspace.

    Args:
        workspace_id_or_key (str | UUID): The workspace identifier.

    Returns:
        Workspace: The Workspace object.
    """
    params: dict[str, str] = {}
    if org_id:
        params = {"org_id": str(org_id)}
    response = self.request("GET", f"/workspaces/{workspace_id_or_key!s}", params=params)
    return Workspace(**response.json())
```


</Accordion>

### get\_workspace\_data\_credentials

```python
get_workspace_data_credentials(
    workspace_id: UUID | None = None,
) -> UserDataCredentials
```

Retrieves user data credentials for secondary storage access.

**Returns:**

* `UserDataCredentials`
  –The user data credentials object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def get_workspace_data_credentials(
    self,
    workspace_id: UUID | None = None,
) -> UserDataCredentials:
    """
    Retrieves user data credentials for secondary storage access.

    Returns:
        The user data credentials object.
    """
    params: dict[str, str] = {}
    if workspace_id:
        params["workspace_id"] = str(workspace_id)
    response = self.request("GET", "/user-data/credentials", params=params)
    return UserDataCredentials(**response.json())
```


</Accordion>

### list\_organizations

```python
list_organizations() -> list[Organization]
```

Retrieves a list of organizations the user belongs to.

**Returns:**

* `list[Organization]`
  –A list of organization names.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def list_organizations(self) -> list[Organization]:
    """
    Retrieves a list of organizations the user belongs to.

    Returns:
        A list of organization names.
    """
    response = self.request("GET", "/organizations")
    return [Organization(**org) for org in response.json()]
```


</Accordion>

### list\_projects

```python
list_projects() -> list[Project]
```

Retrieves a list of projects.

**Returns:**

* `list[Project]`
  –list[Project]: A list of Project objects.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def list_projects(self) -> list[Project]:
    """Retrieves a list of projects.

    Returns:
        list[Project]: A list of Project objects.
    """
    response = self.request("GET", "/strikes/projects")
    return [Project(**project) for project in response.json()]
```


</Accordion>

### list\_runs

```python
list_runs(project: str) -> list[RunSummary]
```

Lists all runs for a specific project.

**Parameters:**

* **`project`**
  (`str`)
  –The project identifier.

**Returns:**

* `list[RunSummary]`
  –A list of RunSummary objects representing the runs in the project.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def list_runs(self, project: str) -> list[RunSummary]:
    """
    Lists all runs for a specific project.

    Args:
        project: The project identifier.

    Returns:
        A list of RunSummary objects representing the runs in the project.
    """
    response = self.request("GET", f"/strikes/projects/{project!s}/runs")
    return [RunSummary(**run) for run in response.json()]
```


</Accordion>

### list\_workspaces

```python
list_workspaces(
    filters: WorkspaceFilter | None = None,
) -> list[Workspace]
```

Retrieves a list of workspaces the user has access to.

**Returns:**

* `list[Workspace]`
  –A list of workspace names.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def list_workspaces(self, filters: WorkspaceFilter | None = None) -> list[Workspace]:
    """
    Retrieves a list of workspaces the user has access to.

    Returns:
        A list of workspace names.
    """
    response = self.request(
        "GET", "/workspaces", params=filters.model_dump() if filters else None
    )
    paginated_workspaces = PaginatedWorkspaces(**response.json())
    # handle the pagination
    all_workspaces: list[Workspace] = paginated_workspaces.workspaces.copy()
    while paginated_workspaces.has_next:
        response = self.request(
            "GET",
            "/workspaces",
            params={
                "page": paginated_workspaces.page + 1,
                "limit": paginated_workspaces.limit,
                **(filters.model_dump() if filters else {}),
            },
        )
        next_page = PaginatedWorkspaces(**response.json())
        all_workspaces.extend(next_page.workspaces)
        paginated_workspaces.page = next_page.page
        paginated_workspaces.has_next = next_page.has_next

    return all_workspaces
```


</Accordion>

### poll\_for\_token

```python
poll_for_token(
    device_code: str,
    interval: int = DEFAULT_POLL_INTERVAL,
    max_poll_time: int = DEFAULT_MAX_POLL_TIME,
) -> AccessRefreshTokenResponse
```

Poll for the access token with the given device code.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def poll_for_token(
    self,
    device_code: str,
    interval: int = DEFAULT_POLL_INTERVAL,
    max_poll_time: int = DEFAULT_MAX_POLL_TIME,
) -> AccessRefreshTokenResponse:
    """Poll for the access token with the given device code."""

    start_time = datetime.now(timezone.utc)
    while (datetime.now(timezone.utc) - start_time).total_seconds() < max_poll_time:
        response = self._request(
            "POST", "/auth/device/token", json_data={"device_code": device_code}
        )

        if response.status_code == 200:
            return AccessRefreshTokenResponse(**response.json())
        if response.status_code != 401:
            raise RuntimeError(self._get_error_message(response))

        time.sleep(interval)

    raise RuntimeError("Polling for token timed out")
```


</Accordion>

### request

```python
request(
    method: str,
    path: str,
    params: dict[str, Any] | None = None,
    json_data: dict[str, Any] | None = None,
) -> httpx.Response
```

Makes an HTTP request to the API and raises exceptions for errors.

**Parameters:**

* **`method`**
  (`str`)
  –The HTTP method (e.g., "GET", "POST").
* **`path`**
  (`str`)
  –The API endpoint path.
* **`params`**
  (`dict[str, Any] | None`, default:
  `None`
  )
  –Query parameters for the request. Defaults to None.
* **`json_data`**
  (`dict[str, Any] | None`, default:
  `None`
  )
  –JSON payload for the request. Defaults to None.

**Returns:**

* `Response`
  –httpx.Response: The HTTP response object.

**Raises:**

* `RuntimeError`
  –If the response status code indicates an error.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def request(
    self,
    method: str,
    path: str,
    params: dict[str, t.Any] | None = None,
    json_data: dict[str, t.Any] | None = None,
) -> httpx.Response:
    """
    Makes an HTTP request to the API and raises exceptions for errors.

    Args:
        method (str): The HTTP method (e.g., "GET", "POST").
        path (str): The API endpoint path.
        params (dict[str, Any] | None, optional): Query parameters for the request. Defaults to None.
        json_data (dict[str, Any] | None, optional): JSON payload for the request. Defaults to None.

    Returns:
        httpx.Response: The HTTP response object.

    Raises:
        RuntimeError: If the response status code indicates an error.
    """

    response = self._request(method, path, params, json_data)

    try:
        response.raise_for_status()
    except httpx.HTTPStatusError as e:
        raise RuntimeError(self._get_error_message(response)) from e

    return response
```


</Accordion>

### update\_dataset\_version

```python
update_dataset_version(
    dataset_id: UUID, new_version: str
) -> UpdateDatasetVersionResponse
```

Updates the version of a specific dataset.

**Parameters:**

* **`dataset_id`**
  (`UUID`)
  –The dataset identifier.
* **`new_version`**
  (`str`)
  –The new version string.

**Returns:**

* **`UpdateDatasetVersionResponse`** ( `UpdateDatasetVersionResponse`
  ) –The response containing updated dataset metadata and credentials.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def update_dataset_version(
    self, dataset_id: UUID, new_version: str
) -> UpdateDatasetVersionResponse:
    """
    Updates the version of a specific dataset.

    Args:
        dataset_id (UUID): The dataset identifier.
        new_version (str): The new version string.

    Returns:
        UpdateDatasetVersionResponse: The response containing updated dataset metadata and credentials.
    """
    payload = {"version": new_version}
    response = self.request("PATCH", f"/datasets/{dataset_id}/version", json_data=payload)
    return UpdateDatasetVersionResponse(**response.json())
```


</Accordion>

### upload\_complete

```python
upload_complete(
    request: DatasetUploadCompleteRequest,
) -> DatasetMetadata
```

Marks a dataset upload as complete.

**Parameters:**

* **`request`**
  (`DatasetUploadComplete`)
  –The dataset upload completion request object.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def upload_complete(self, request: DatasetUploadCompleteRequest) -> DatasetMetadata:
    """
    Marks a dataset upload as complete.

    Args:
        request (DatasetUploadComplete): The dataset upload completion request object.
    """

    response = self.request(
        "POST", "/datasets/upload-complete", json_data=request.model_dump(mode="json")
    )
    return DatasetMetadata(**response.json())
```


</Accordion>

### url\_for\_user\_code

```python
url_for_user_code(user_code: str) -> str
```

Get the URL to verify the user code.

<Accordion title="Source code in dreadnode/api/client.py" icon="code">
```python
def url_for_user_code(self, user_code: str) -> str:
    """Get the URL to verify the user code."""

    return f"{self._base_url.removesuffix('/api')}/account/device?code={user_code}"
```


</Accordion>
ExportFormat
------------

```python
ExportFormat = Literal['csv', 'json', 'jsonl', 'parquet']
```

Available export formats for traces and runs

MetricAggregationType
---------------------

```python
MetricAggregationType = Literal[
    "avg",
    "median",
    "min",
    "max",
    "sum",
    "first",
    "last",
    "count",
    "std",
    "var",
]
```

How to aggregate metrics in traces and runs

Object
------

```python
Object = ObjectVal | ObjectUri
```

Represents an object (input/output) in a run or task.

SpanStatus
----------

```python
SpanStatus = Literal['pending', 'completed', 'failed']
```

Status of a span in the trace

StatusFilter
------------

```python
StatusFilter = Literal['all', 'completed', 'failed']
```

Filter for trace and run statuses

TimeAggregationType
-------------------

```python
TimeAggregationType = Literal['max', 'min', 'sum', 'count']
```

How to aggregate time in traces and runs

TimeAxisType
------------

```python
TimeAxisType = Literal['wall', 'relative', 'step']
```

Type of time axis for traces and runs

ArtifactDir
-----------

Represents a directory entry for artifacts.

### children

```python
children: list[Union[ArtifactDir, ArtifactFile]]
```

List of child artifacts, which can be files or subdirectories.

### dir\_path

```python
dir_path: str
```

Path to the directory.

### hash

```python
hash: str
```

Hash of the directory, used for deduplication.

ArtifactFile
------------

Represents a file entry for artifacts.

### final\_real\_path

```python
final_real_path: str
```

Real path of the original file.

### hash

```python
hash: str
```

Hash of the file, used for deduplication.

### size\_bytes

```python
size_bytes: int
```

Size of the file in bytes.

### uri

```python
uri: str
```

URI where the file is stored (e.g. s3://...).

CreateDatasetRequest
--------------------

A data model representing the request body for creating a new dataset.

### key

```python
key: Annotated[str, BeforeValidator(_validate_key)]
```

Unique identifier of the dataset.

### org\_key

```python
org_key: Annotated[str, BeforeValidator(_validate_key)]
```

Unique identifier for the organization owning the dataset.

### tags

```python
tags: list[str] = Field(
    default_factory=list,
    description="Optional list of tags associated with the dataset.",
)
```

Optional list of tags associated with the dataset.

### version

```python
version: Annotated[str, BeforeValidator(_validate_version)]
```

Version of the dataset following semantic versioning.

CreateDatasetResponse
---------------------

A data model representing the response after creating a new dataset.

**Attributes:**

* **`id`**
  (`str`)
  –Unique identifier for the dataset.
* **`upload_uri`**
  (`str`)
  –URI to upload the dataset files.
* **`status_code`**
  (`int`)
  –HTTP status code of the upload request.

### dataset\_id

```python
dataset_id: UUID
```

Unique identifier for the dataset.

### user\_data\_access\_response

```python
user_data_access_response: UserDataCredentials
```

URI to upload the dataset files.

DatasetDownloadRequest
----------------------

A data model representing the request body for downloading a dataset.

### dataset\_uri

```python
dataset_uri: str
```

Name of the dataset to download.

### version

```python
version: str
```

Version of the dataset to download. If None, the latest version is downloaded.

DatasetMetadata
---------------

A data model representing the metadata of a dataset.

### download\_count

```python
download_count: int | None = Field(
    None,
    description="Number of times dataset has been downloaded",
)
```

Number of times dataset has been downloaded.

### version

```python
version: Annotated[
    str, BeforeValidator(_validate_version)
] = Field(..., description="Dataset version")
```

Version of the dataset following semantic versioning.

DatasetUploadCompleteRequest
----------------------------

A data model representing the request body for completing a dataset upload.

### complete

```python
complete: bool
```

Status code indicating the result of the upload.

### dataset\_id

```python
dataset_id: UUID
```

Unique identifier for the dataset.

Metric
------

Metric data for a span in a trace.

### attributes

```python
attributes: AnyDict
```

Attributes associated with the metric, e.g., labels, tags.

### step

```python
step: int
```

Step or iteration number for the metric.

### timestamp

```python
timestamp: datetime
```

Timestamp when the metric was recorded.

### value

```python
value: float | None
```

Value of the metric.

ObjectRef
---------

Reference to an object in a run or task.

### hash

```python
hash: str
```

Hash of the object, used for deduplication and content tracking.

### label

```python
label: str
```

Label for the object.

### name

```python
name: str
```

Name of the object.

ObjectUri
---------

Represents a URI object in a run or task - stored in a remote filesystem.

### hash

```python
hash: str = Field(repr=False)
```

Hash of the object, used for deduplication and content tracking.

### label

```python
label: str
```

Label for the object.

### name

```python
name: str
```

Name of the object.

### schema\_

```python
schema_: AnyDict
```

Schema of the object, describing its structure.

### schema\_hash

```python
schema_hash: str = Field(repr=False)
```

Hash of the schema, used for deduplication.

### size

```python
size: int
```

Size of the object in bytes.

### uri

```python
uri: str
```

URI where the object is stored (e.g. s3://...).

### value

```python
value: Any
```

The actual value of the object, fetched from the URI if not already cached.

ObjectVal
---------

Represents a value object in a run or task.

### hash

```python
hash: str = Field(repr=False)
```

Hash of the object, used for deduplication and content tracking.

### label

```python
label: str
```

Label for the object.

### name

```python
name: str
```

Name of the object.

### schema\_

```python
schema_: AnyDict
```

Schema of the object, describing its structure.

### schema\_hash

```python
schema_hash: str = Field(repr=False)
```

Hash of the schema, used for deduplication.

### value

```python
value: Any
```

The actual value of the object, can be any type.

Organization
------------

### allow\_external\_invites

```python
allow_external_invites: bool
```

Allow external invites to the organization?

### created\_at

```python
created_at: datetime
```

Creation timestamp.

### description

```python
description: str | None
```

Description of the organization.

### id

```python
id: UUID
```

Unique identifier for the organization.

### is\_active

```python
is_active: bool
```

Is the organization active?

### key

```python
key: str
```

URL-friendly identifier for the organization.

### max\_members

```python
max_members: int
```

Maximum number of members allowed in the organization.

### name

```python
name: str
```

Name of the organization.

### updated\_at

```python
updated_at: datetime
```

Last update timestamp.

PaginatedWorkspaces
-------------------

### has\_next

```python
has_next: bool
```

Is there a next page available?

### has\_previous

```python
has_previous: bool
```

Is there a previous page available?

### limit

```python
limit: int
```

Number of workspaces per page.

### page

```python
page: int
```

Current page number.

### total

```python
total: int
```

Total number of workspaces available.

### total\_pages

```python
total_pages: int
```

Total number of pages available.

### workspaces

```python
workspaces: list[Workspace]
```

List of workspaces in the current page.

Project
-------

Project metadata, containing information about the project.

### created\_at

```python
created_at: datetime
```

Timestamp when the project was created.

### description

```python
description: str | None = Field(repr=False)
```

Description of the project.

### id

```python
id: UUID = Field(repr=False)
```

Unique identifier for the project.

### key

```python
key: str
```

Key for the project, used for authentication.

### last\_run

```python
last_run: RawRun | None = Field(repr=False)
```

Last run associated with the project, if any.

### name

```python
name: str
```

Name of the project.

### run\_count

```python
run_count: int
```

Number of runs associated with the project.

### updated\_at

```python
updated_at: datetime
```

Timestamp when the project was last updated.

### workspace\_id

```python
workspace_id: UUID | None
```

Unique identifier for the workspace the project belongs to.

Run
---

Detailed information about a run, including inputs, outputs, and artifacts.

### artifacts

```python
artifacts: list[ArtifactDir] = Field(repr=False)
```

Artifacts associated with the run, including files and directories.

### inputs

```python
inputs: dict[str, Object] = Field(repr=False)
```

Inputs logged for the run with log\_input().

### outputs

```python
outputs: dict[str, Object] = Field(repr=False)
```

Outputs logged for the run with log\_output().

RunSummary
----------

Summary of a run, containing metadata and basic information.

### duration

```python
duration: int
```

Duration of the run in milliseconds.

### exception

```python
exception: SpanException | None
```

Exception details if the run failed.

### id

```python
id: ULID | str
```

Unique identifier for the run.

### metrics

```python
metrics: dict[str, list[Metric]] = Field(repr=False)
```

Metrics logged for the run with log\_metric().

### name

```python
name: str
```

Name of the run.

### params

```python
params: AnyDict = Field(repr=False)
```

Parameters logged for the run with log\_param().

### span\_id

```python
span_id: str = Field(repr=False)
```

Unique identifier for the run's span in the trace.

### status

```python
status: SpanStatus
```

Status of the run, e.g., 'completed', 'failed'.

### tags

```python
tags: set[str]
```

Set of tags associated with the run.

### timestamp

```python
timestamp: datetime
```

Timestamp when the run started.

### trace\_id

```python
trace_id: str = Field(repr=False)
```

Unique identifier for the trace this run belongs to.

SpanEvent
---------

OTEL event for a span in a trace.

SpanException
-------------

Exception details for a span in a trace.

SpanLink
--------

OTEL link for a span in a trace.

Task
----

Detailed information about a task, including inputs and outputs.

### inputs

```python
inputs: dict[str, Object] = Field(repr=False)
```

Inputs logged for the task with log\_input() or autologging.

### outputs

```python
outputs: dict[str, Object] = Field(repr=False)
```

Outputs logged for the task with log\_output() or autologging.

TaskTree
--------

Tree structure representing tasks and their relationships in a trace.

### children

```python
children: list[TaskTree] = []
```

Children of this task.

### task

```python
task: Task
```

Task at this node.

TraceSpan
---------

Span in a trace, representing a single operation or task.

### attributes

```python
attributes: AnyDict = Field(repr=False)
```

Attributes associated with the span.

### duration

```python
duration: int
```

Duration of the span in milliseconds.

### events

```python
events: list[SpanEvent] = Field(repr=False)
```

Events associated with the span, e.g., logs, checkpoints.

### exception

```python
exception: SpanException | None
```

Exception details if the span failed.

### links

```python
links: list[SpanLink] = Field(repr=False)
```

Links to other spans or resources related to this span.

### name

```python
name: str
```

Name of the operation or task represented by the span.

### parent\_span\_id

```python
parent_span_id: str | None = Field(repr=False)
```

ID of the parent span, if any.

### resource\_attributes

```python
resource_attributes: AnyDict = Field(repr=False)
```

Resource attributes for the span, e.g., host, service version.

### service\_name

```python
service_name: str | None = Field(repr=False)
```

Name of the service that generated this span.

### span\_id

```python
span_id: str
```

Unique identifier for the span.

### status

```python
status: SpanStatus
```

Status of the span, e.g., 'completed', 'failed'.

### timestamp

```python
timestamp: datetime
```

Timestamp when the span started.

### trace\_id

```python
trace_id: str = Field(repr=False)
```

Unique identifier for the trace this span belongs to.

TraceTree
---------

Tree structure representing spans and their relationships in a trace.

### children

```python
children: list[TraceTree] = []
```

Children of this span, representing nested spans or tasks.

### span

```python
span: Task | TraceSpan
```

Span at this node, can be a Task or a TraceSpan.

UpdateDatasetVersionResponse
----------------------------

A data model representing the response after updating a dataset version.

### dataset

```python
dataset: DatasetMetadata
```

Updated dataset metadata.

Workspace
---------

### created\_at

```python
created_at: datetime
```

Creation timestamp.

### created\_by

```python
created_by: UUID | None = None
```

Unique identifier for the user who created the workspace.

### description

```python
description: str | None
```

Description of the workspace.

### id

```python
id: UUID
```

Unique identifier for the workspace.

### is\_active

```python
is_active: bool
```

Is the workspace active?

### is\_default

```python
is_default: bool
```

Is the workspace the default one?

### key

```python
key: str
```

Unique key for the workspace.

### name

```python
name: str
```

Name of the workspace.

### org\_id

```python
org_id: UUID
```

Unique identifier for the organization the workspace belongs to.

### org\_name

```python
org_name: str | None
```

Name of the organization the workspace belongs to.

### project\_count

```python
project_count: int | None
```

Number of projects in the workspace.

### updated\_at

```python
updated_at: datetime
```

Last update timestamp.

WorkspaceFilter
---------------

Filter parameters for workspace listing