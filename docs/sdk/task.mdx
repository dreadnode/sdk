---
title: dreadnode.task
---

{/*
::: dreadnode.task
*/}

Task
----

```python
Task(
    func: Callable[P, R],
    tracer: Tracer,
    *,
    name: str | None = None,
    label: str | None = None,
    scorers: ScorersLike[R] | None = None,
    assert_scores: list[str] | Literal[True] | None = None,
    log_inputs: Sequence[str]
    | bool
    | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    log_execution_metrics: bool = False,
    tags: Sequence[str] | None = None,
    attributes: AnyDict | None = None,
    config: dict[str, ConfigInfo] | None = None,
    context: dict[str, Context] | None = None,
)
```

Structured task wrapper for a function that can be executed within a run.

Tasks allow you to associate metadata, inputs, outputs, and metrics for a unit of work.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def __init__(
    self,
    func: t.Callable[P, R],
    tracer: Tracer,
    *,
    name: str | None = None,
    label: str | None = None,
    scorers: ScorersLike[R] | None = None,
    assert_scores: list[str] | t.Literal[True] | None = None,
    log_inputs: t.Sequence[str] | bool | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    log_execution_metrics: bool = False,
    tags: t.Sequence[str] | None = None,
    attributes: AnyDict | None = None,
    config: dict[str, ConfigInfo] | None = None,
    context: dict[str, Context] | None = None,
) -> None:
    unwrapped = inspect.unwrap(func)
    if inspect.isgeneratorfunction(unwrapped) or inspect.isasyncgenfunction(
        unwrapped,
    ):
        raise TypeError("@task cannot be applied to generators")

    func_name = get_callable_name(unwrapped, short=True)
    name = name or func_name
    label = clean_str(label or name)

    attributes = attributes or {}
    attributes["code.function"] = func_name
    with contextlib.suppress(Exception):
        attributes["code.lineno"] = unwrapped.__code__.co_firstlineno
    with contextlib.suppress(Exception):
        attributes.update(
            get_filepath_attribute(
                inspect.getsourcefile(unwrapped),  # type: ignore [arg-type]
            ),
        )

    super().__init__(func, name=name, config=config, context=context)

    self.__dn_attr_config__["scorers"] = ConfigInfo(field_kwargs={"default": scorers})

    self._tracer = tracer

    self.name = name
    "The name of the task. This is used for logging and tracing."
    self.label = label
    "The label of the task - used to group associated metrics and data together."
    self.scorers = Scorer.fit_many(scorers)
    "A list of scorers to evaluate the task's output."
    scorer_names = [s.name for s in self.scorers]
    self.assert_scores = scorer_names if assert_scores is True else list(assert_scores or [])
    "A list of score names to ensure have truthy values, otherwise raise an AssertionFailedError."
    self.tags = list(tags or [])
    "A list of tags to attach to the task span."
    self.attributes = attributes
    "A dictionary of attributes to attach to the task span."
    self.log_inputs = (
        log_inputs if isinstance(log_inputs, bool | Inherited) else list(log_inputs)
    )
    "Log all, or specific, incoming arguments to the function as inputs."
    self.log_output = log_output
    "Log the result of the function as an output."
    self.log_execution_metrics = log_execution_metrics
    "Track execution metrics such as success rate and run count."

    for assertion in self.assert_scores or []:
        if assertion not in scorer_names:
            raise ValueError(
                f"Unknown '{assertion}' in assert_scores, it must be one of {scorer_names}"
            )
```


</Accordion>

### assert\_scores

```python
assert_scores = (
    scorer_names
    if assert_scores is True
    else list(assert_scores or [])
)
```

A list of score names to ensure have truthy values, otherwise raise an AssertionFailedError.

### attributes

```python
attributes = attributes
```

A dictionary of attributes to attach to the task span.

### label

```python
label = label
```

The label of the task - used to group associated metrics and data together.

### log\_execution\_metrics

```python
log_execution_metrics = log_execution_metrics
```

Track execution metrics such as success rate and run count.

### log\_inputs

```python
log_inputs = (
    log_inputs
    if isinstance(log_inputs, bool | Inherited)
    else list(log_inputs)
)
```

Log all, or specific, incoming arguments to the function as inputs.

### log\_output

```python
log_output = log_output
```

Log the result of the function as an output.

### name

```python
name = name
```

The name of the task. This is used for logging and tracing.

### scorers

```python
scorers = fit_many(scorers)
```

A list of scorers to evaluate the task's output.

### tags

```python
tags = list(tags or [])
```

A list of tags to attach to the task span.

### as\_target

```python
as_target(
    input_param_name: str | None = None,
) -> CustomTarget[R]
```

Convert this task into a CustomTarget that can be used in AIRT attack patterns.

**Parameters:**

* **`input_param_name`**
  (`str | None`, default:
  `None`
  )
  –The name of the parameter in the task's signature where the attack input should be injected.
  Otherwise the first non-optional parameter will be used, or no injection will occur.

**Returns:**

* `CustomTarget[R]`
  –A CustomTarget wrapping this task.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def as_target(
    self,
    input_param_name: str | None = None,
) -> "CustomTarget[R]":
    """
    Convert this task into a CustomTarget that can be used in AIRT attack patterns.

    Args:
        input_param_name: The name of the parameter in the task's signature where the attack input should be injected.
                          Otherwise the first non-optional parameter will be used, or no injection will occur.

    Returns:
        A CustomTarget wrapping this task.
    """
    from dreadnode.airt.target.custom import CustomTarget

    return CustomTarget(task=self, input_param_name=input_param_name)
```


</Accordion>

### clone

```python
clone() -> Task[P, R]
```

Clone a task.

**Returns:**

* `Task[P, R]`
  –A new Task instance with the same attributes as this one.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def clone(self) -> "Task[P, R]":
    """
    Clone a task.

    Returns:
        A new Task instance with the same attributes as this one.
    """
    return self.__deepcopy__({})
```


</Accordion>

### many

```python
many(count: int, *args: args, **kwargs: kwargs) -> list[R]
```

Run the task multiple times and return a list of outputs.

**Parameters:**

* **`count`**
  (`int`)
  –The number of times to run the task.
* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task.

**Returns:**

* `list[R]`
  –A list of outputs from each task execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def many(self, count: int, *args: P.args, **kwargs: P.kwargs) -> list[R]:
    """
    Run the task multiple times and return a list of outputs.

    Args:
        count: The number of times to run the task.
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task.

    Returns:
        A list of outputs from each task execution.
    """
    async with self.stream_many(count, *args, **kwargs) as stream:
        return [span.output async for span in stream]
```


</Accordion>

### map

```python
map(
    args: list[Any] | dict[str, Any | list[Any]],
    *,
    concurrency: int | None = None,
) -> list[R]
```

Runs this task multiple times by mapping over iterable arguments.

**Examples:**

```python
@dn.task
async def my_task(input: str, *, suffix: str = "") -> str:
    return f"Processed {input}{suffix}"

# Map over a list of basic inputs
await task.map_run(["1", "2", "3"])

# Map over a dict of parameters
await task.map_run({
    "input": ["1", "2", "3"],
    "suffix": ["_a", "_b", "_c"]
})
```

**Parameters:**

* **`args`**
  (`list[Any] | dict[str, Any | list[Any]]`)
  –Either a flat list of the first positional argument, or a dict
  where each key is a parameter name and the value is either a single value
  or a list of values to map over.
* **`concurrency`**
  (`int | None`, default:
  `None`
  )
  –The maximum number of tasks to run in parallel.
  If None, runs with unlimited concurrency.

**Returns:**

* `list[R]`
  –A TaskSpanList containing the results of each execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def map(
    self,
    args: list[t.Any] | dict[str, t.Any | list[t.Any]],
    *,
    concurrency: int | None = None,
) -> list[R]:
    """
    Runs this task multiple times by mapping over iterable arguments.

    Examples:
        ~~~python

        @dn.task
        async def my_task(input: str, *, suffix: str = "") -> str:
            return f"Processed {input}{suffix}"

        # Map over a list of basic inputs
        await task.map_run(["1", "2", "3"])

        # Map over a dict of parameters
        await task.map_run({
            "input": ["1", "2", "3"],
            "suffix": ["_a", "_b", "_c"]
        })
        ~~~

    Args:
        args: Either a flat list of the first positional argument, or a dict
              where each key is a parameter name and the value is either a single value
              or a list of values to map over.
        concurrency: The maximum number of tasks to run in parallel.
                     If None, runs with unlimited concurrency.

    Returns:
        A TaskSpanList containing the results of each execution.
    """
    async with self.stream_map(args, concurrency=concurrency) as stream:
        return [span.output async for span in stream]
```


</Accordion>

### retry

```python
retry(count: int, *args: args, **kwargs: kwargs) -> R
```

Run the task up to `count` times, returning the output of the first
successful execution, otherwise raise the most recent exception.

This is a powerful pattern for non-deterministic tasks where multiple
attempts may be needed to generate a valid output according to the
task's `assert_scores`. However, it can also be useful as a retry
mechanism for transient errors.

**Parameters:**

* **`count`**
  (`int`)
  –The maximum number of times to run the task.
* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task.

**Returns:**

* `R`
  –The output of the first successful and valid task execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def retry(
    self,
    count: int,
    *args: P.args,
    **kwargs: P.kwargs,
) -> R:
    """
    Run the task up to `count` times, returning the output of the first
    successful execution, otherwise raise the most recent exception.

    This is a powerful pattern for non-deterministic tasks where multiple
    attempts may be needed to generate a valid output according to the
    task's `assert_scores`. However, it can also be useful as a retry
    mechanism for transient errors.

    Args:
        count: The maximum number of times to run the task.
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task.

    Returns:
        The output of the first successful and valid task execution.
    """
    last_span = None
    for _ in range(count):
        span = await self.run_always(*args, **kwargs)
        last_span = span
        if span.exception is None:
            return span.output

        # If the loop finishes, all attempts failed. Raise the exception
        # from the final attempt for debugging.
        last_span.raise_if_failed()

    # Just for type checking - should never be called
    raise RuntimeError("Generation failed to produce a valid result.")
```


</Accordion>

### run

```python
run(*args: args, **kwargs: kwargs) -> TaskSpan[R]
```

Execute the task and return the result as a TaskSpan.
If the task fails, an exception is raised.

**Parameters:**

* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def run(self, *args: P.args, **kwargs: P.kwargs) -> TaskSpan[R]:
    """
    Execute the task and return the result as a TaskSpan.
    If the task fails, an exception is raised.

    Args:
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task
    """
    span = await self.run_always(*args, **kwargs)
    span.raise_if_failed()
    return span
```


</Accordion>

### run\_always

```python
run_always(*args: args, **kwargs: kwargs) -> TaskSpan[R]
```

Execute the task and return the result as a TaskSpan.

Note, if the task fails, the span will still be returned with the exception set.

**Parameters:**

* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task.

**Returns:**

* `TaskSpan[R]`
  –The span associated with task execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def run_always(self, *args: P.args, **kwargs: P.kwargs) -> TaskSpan[R]:
    """
    Execute the task and return the result as a TaskSpan.

    Note, if the task fails, the span will still be returned with the exception set.

    Args:
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task.

    Returns:
        The span associated with task execution.
    """
    from dreadnode import score

    run = current_run_span.get()

    log_inputs = (
        (run.autolog if run else False)
        if isinstance(self.log_inputs, Inherited)
        else self.log_inputs
    )
    log_output = (
        (run.autolog if run else False)
        if isinstance(self.log_output, Inherited)
        else self.log_output
    )

    ctx_inputs_to_log = t.cast("AnyDict", kwargs.pop("__dn_ctx_inputs__", {}))

    task_span = TaskSpan[R](
        name=self.name,
        label=self.label,
        attributes=self.attributes,
        tags=self.tags,
        run_id=run.run_id if run else "",
        tracer=self._tracer,
        arguments=Arguments(args, kwargs),
    )

    with contextlib.suppress(Exception), task_span as span:
        bound_args = self._bind_args(*args, **kwargs)
        bound_args_dict = dict(bound_args.arguments)

        inputs_to_log = (
            bound_args_dict
            if log_inputs is True
            else {k: v for k, v in bound_args_dict.items() if k in log_inputs}
            if log_inputs is not False
            else {}
        )

        # If log_inputs is inherited, filter out items that don't seem useful
        # to serialize like `None` or repr fallbacks.
        if isinstance(self.log_inputs, Inherited):
            inputs_to_log = {
                k: v for k, v in inputs_to_log.items() if seems_useful_to_serialize(v)
            }

        if run and self.log_execution_metrics:
            run.log_metric(
                "count",
                1,
                prefix=f"{self.label}.exec",
                mode="count",
                attributes={"auto": True},
            )

        input_object_hashes: list[str] = [
            span.log_input(
                name,
                value,
                attributes={"auto": True},
            )
            for name, value in inputs_to_log.items()
        ]

        for name, value in ctx_inputs_to_log.items():
            span.log_input(
                name,
                value,
                attributes={"auto": True, "ctx": True},
            )

        output = t.cast("R | t.Awaitable[R]", self.func(*bound_args.args, **bound_args.kwargs))
        if inspect.isawaitable(output):
            output = await output

        span.output = output

        # Log the output

        if (
            run
            and log_output
            and (
                not isinstance(self.log_inputs, Inherited) or seems_useful_to_serialize(output)
            )
        ):
            output_object_hash = span.log_output(
                "output",
                output,
                attributes={"auto": True},
            )

            # Link the output to the inputs
            for input_object_hash in input_object_hashes:
                run.link_objects(output_object_hash, input_object_hash)

        # Score and check assertions

        await score(output, self.scorers, assert_scores=self.assert_scores)

    if run and self.log_execution_metrics:
        run.log_metric(
            "success_rate",
            0 if span.exception else 1,
            prefix=f"{self.label}.exec",
            mode="avg",
            attributes={"auto": True},
        )

    # Trigger a run update whenever a task completes
    if run is not None:
        run.push_update()

    return span
```


</Accordion>

### stream\_many

```python
stream_many(
    count: int, *args: args, **kwargs: kwargs
) -> t.AsyncContextManager[
    t.AsyncGenerator[TaskSpan[R], None]
]
```

Run the task multiple times concurrently and yield each TaskSpan as it completes.

**Parameters:**

* **`count`**
  (`int`)
  –The number of times to run the task.
* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task

**Yields:**

* `AsyncContextManager[AsyncGenerator[TaskSpan[R], None]]`
  –TaskSpan for each task execution, or an Exception if the task fails.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def stream_many(
    self,
    count: int,
    *args: P.args,
    **kwargs: P.kwargs,
) -> t.AsyncContextManager[t.AsyncGenerator[TaskSpan[R], None]]:
    """
    Run the task multiple times concurrently and yield each TaskSpan as it completes.

    Args:
        count: The number of times to run the task.
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task

    Yields:
        TaskSpan for each task execution, or an Exception if the task fails.
    """
    tasks = [self.run_always(*args, **kwargs) for _ in range(count)]
    return concurrent_gen(tasks)
```


</Accordion>

### stream\_map

```python
stream_map(
    args: list[Any] | dict[str, Any | list[Any]],
    *,
    concurrency: int | None = None,
) -> t.AsyncContextManager[
    t.AsyncGenerator[TaskSpan[R], None]
]
```

Runs this task multiple times by mapping over iterable arguments.

**Parameters:**

* **`args`**
  (`list[Any] | dict[str, Any | list[Any]]`)
  –Either a flat list of the first positional argument, or a dict
  where each key is a parameter name and the value is either a single value
  or a list of values to map over.
* **`concurrency`**
  (`int | None`, default:
  `None`
  )
  –The maximum number of tasks to run in parallel.
  If None, runs with unlimited concurrency.

**Returns:**

* `AsyncContextManager[AsyncGenerator[TaskSpan[R], None]]`
  –A TaskSpanList containing the results of each execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def stream_map(
    self,
    args: list[t.Any] | dict[str, t.Any | list[t.Any]],
    *,
    concurrency: int | None = None,
) -> t.AsyncContextManager[t.AsyncGenerator[TaskSpan[R], None]]:
    """
    Runs this task multiple times by mapping over iterable arguments.

    Args:
        args: Either a flat list of the first positional argument, or a dict
              where each key is a parameter name and the value is either a single value
              or a list of values to map over.
        concurrency: The maximum number of tasks to run in parallel.
                     If None, runs with unlimited concurrency.

    Returns:
        A TaskSpanList containing the results of each execution.
    """
    arguments = self._prepare_map_args(args)
    tasks = [self.run_always(*args.args, **args.kwargs) for args in arguments]
    return concurrent_gen(tasks, concurrency)
```


</Accordion>

### try\_

```python
try_(*args: args, **kwargs: kwargs) -> R | None
```

Attempt to run the task and return the result.
If the task fails, None is returned.

**Parameters:**

* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task.

**Returns:**

* `R | None`
  –The output of the task, or None if the task failed.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def try_(self, *args: P.args, **kwargs: P.kwargs) -> R | None:
    """
    Attempt to run the task and return the result.
    If the task fails, None is returned.

    Args:
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task.

    Returns:
        The output of the task, or None if the task failed.
    """
    span = await self.run_always(*args, **kwargs)
    with contextlib.suppress(Exception):
        return span.output
    return None
```


</Accordion>

### try\_many

```python
try_many(
    count: int, *args: args, **kwargs: kwargs
) -> list[R]
```

Attempt to run the task multiple times and return a list of outputs.
If any task fails, its result is excluded from the output.

**Parameters:**

* **`count`**
  (`int`)
  –The number of times to run the task.
* **`args`**
  (`args`, default:
  `()`
  )
  –The arguments to pass to the task.
* **`kwargs`**
  (`kwargs`, default:
  `{}`
  )
  –The keyword arguments to pass to the task.

**Returns:**

* `list[R]`
  –A list of outputs from each task execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def try_many(
    self,
    count: int,
    *args: P.args,
    **kwargs: P.kwargs,
) -> list[R]:
    """
    Attempt to run the task multiple times and return a list of outputs.
    If any task fails, its result is excluded from the output.

    Args:
        count: The number of times to run the task.
        args: The arguments to pass to the task.
        kwargs: The keyword arguments to pass to the task.

    Returns:
        A list of outputs from each task execution.
    """
    async with self.stream_many(count, *args, **kwargs) as stream:
        return [span.output async for span in stream if span.exception is None]
```


</Accordion>

### try\_map

```python
try_map(
    args: list[Any] | dict[str, Any | list[Any]],
    *,
    concurrency: int | None = None,
) -> list[R]
```

Attempt to run this task multiple times by mapping over iterable arguments.
If any task fails, its result is excluded from the output.

**Parameters:**

* **`args`**
  (`list[Any] | dict[str, Any | list[Any]]`)
  –Either a flat list of the first positional argument, or a dict
  where each key is a parameter name and the value is either a single value
  or a list of values to map over.
* **`concurrency`**
  (`int | None`, default:
  `None`
  )
  –The maximum number of tasks to run in parallel.
  If None, runs with unlimited concurrency.

**Returns:**

* `list[R]`
  –A TaskSpanList containing the results of each execution.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
async def try_map(
    self,
    args: list[t.Any] | dict[str, t.Any | list[t.Any]],
    *,
    concurrency: int | None = None,
) -> list[R]:
    """
    Attempt to run this task multiple times by mapping over iterable arguments.
    If any task fails, its result is excluded from the output.

    Args:
        args: Either a flat list of the first positional argument, or a dict
              where each key is a parameter name and the value is either a single value
              or a list of values to map over.
        concurrency: The maximum number of tasks to run in parallel.
                     If None, runs with unlimited concurrency.

    Returns:
        A TaskSpanList containing the results of each execution.
    """
    async with self.stream_map(args, concurrency=concurrency) as stream:
        return [span.output async for span in stream if span.exception is None]
```


</Accordion>

### with\_

```python
with_(
    *,
    scorers: Sequence[Scorer[R] | ScorerCallable[R]]
    | None = None,
    assert_scores: Sequence[str]
    | Literal[True]
    | None = None,
    name: str | None = None,
    tags: Sequence[str] | None = None,
    label: str | None = None,
    log_inputs: Sequence[str]
    | bool
    | Inherited
    | None = None,
    log_output: bool | Inherited | None = None,
    log_execution_metrics: bool | None = None,
    append: bool = False,
    attributes: AnyDict | None = None,
) -> Task[P, R]
```

Clone a task and modify its attributes.

**Parameters:**

* **`scorers`**
  (`Sequence[Scorer[R] | ScorerCallable[R]] | None`, default:
  `None`
  )
  –A list of new scorers to set or append to the task.
* **`assert_scores`**
  (`Sequence[str] | Literal[True] | None`, default:
  `None`
  )
  –A list of new assertion names to set or append to the task.
* **`name`**
  (`str | None`, default:
  `None`
  )
  –The new name for the task.
* **`tags`**
  (`Sequence[str] | None`, default:
  `None`
  )
  –A list of new tags to set or append to the task.
* **`label`**
  (`str | None`, default:
  `None`
  )
  –The new label for the task.
* **`log_inputs`**
  (`Sequence[str] | bool | Inherited | None`, default:
  `None`
  )
  –Log all, or specific, incoming arguments to the function as inputs.
* **`log_output`**
  (`bool | Inherited | None`, default:
  `None`
  )
  –Log the result of the function as an output.
* **`log_execution_metrics`**
  (`bool | None`, default:
  `None`
  )
  –Log execution metrics such as success rate and run count.
* **`append`**
  (`bool`, default:
  `False`
  )
  –If True, appends the new scorers and tags to the existing ones. If False, replaces them.
* **`attributes`**
  (`AnyDict | None`, default:
  `None`
  )
  –Additional attributes to set or update in the task.

**Returns:**

* `Task[P, R]`
  –A new Task instance with the modified attributes.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def with_(
    self,
    *,
    scorers: t.Sequence[Scorer[R] | ScorerCallable[R]] | None = None,
    assert_scores: t.Sequence[str] | t.Literal[True] | None = None,
    name: str | None = None,
    tags: t.Sequence[str] | None = None,
    label: str | None = None,
    log_inputs: t.Sequence[str] | bool | Inherited | None = None,
    log_output: bool | Inherited | None = None,
    log_execution_metrics: bool | None = None,
    append: bool = False,
    attributes: AnyDict | None = None,
) -> "Task[P, R]":
    """
    Clone a task and modify its attributes.

    Args:
        scorers: A list of new scorers to set or append to the task.
        assert_scores: A list of new assertion names to set or append to the task.
        name: The new name for the task.
        tags: A list of new tags to set or append to the task.
        label: The new label for the task.
        log_inputs: Log all, or specific, incoming arguments to the function as inputs.
        log_output: Log the result of the function as an output.
        log_execution_metrics: Log execution metrics such as success rate and run count.
        append: If True, appends the new scorers and tags to the existing ones. If False, replaces them.
        attributes: Additional attributes to set or update in the task.

    Returns:
        A new Task instance with the modified attributes.
    """
    task = self.clone()
    task.name = name or task.name
    task.label = label or task.label
    task.log_inputs = (
        task.log_inputs
        if log_inputs is None
        else log_inputs
        if isinstance(log_inputs, (bool | Inherited))
        else list(log_inputs)
    )
    task.log_output = task.log_output if log_output is None else log_output
    task.log_execution_metrics = (
        log_execution_metrics
        if log_execution_metrics is not None
        else task.log_execution_metrics
    )

    new_scorers = Scorer.fit_many(scorers or [])
    new_tags = list(tags or [])
    new_assert_scores = (
        [s.name for s in new_scorers] if assert_scores is True else list(assert_scores or [])
    )

    if append:
        task.scorers.extend(new_scorers)
        task.tags.extend(new_tags)
        task.assert_scores.extend(new_assert_scores)
        task.attributes.update(attributes or {})
    else:
        task.scorers = new_scorers
        task.tags = new_tags
        task.assert_scores = new_assert_scores
        task.attributes = attributes or {}

    return task
```


</Accordion>

TaskFailedWarning
-----------------

Warning related to task execution failures.

TaskSpanList
------------

Lightweight wrapper around a list of TaskSpans to provide some convenience methods.

### sorted

```python
sorted(*, reverse: bool = True) -> TaskSpanList[R]
```

Sorts the spans in this list by their average metric value.

**Parameters:**

* **`reverse`**
  (`bool`, default:
  `True`
  )
  –If True, sorts in descending order. Defaults to True.

**Returns:**

* `TaskSpanList[R]`
  –A new TaskSpanList sorted by average metric value.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def sorted(self, *, reverse: bool = True) -> "TaskSpanList[R]":
    """
    Sorts the spans in this list by their average metric value.

    Args:
        reverse: If True, sorts in descending order. Defaults to True.

    Returns:
        A new TaskSpanList sorted by average metric value.
    """
    return TaskSpanList(
        sorted(
            self,
            key=lambda span: span.get_average_metric_value(),
            reverse=reverse,
        ),
    )
```


</Accordion>

### top\_n

```python
top_n(
    n: int,
    *,
    as_outputs: Literal[False] = False,
    reverse: bool = True,
) -> TaskSpanList[R]
```

```python
top_n(
    n: int,
    *,
    as_outputs: Literal[True],
    reverse: bool = True,
) -> list[R]
```

```python
top_n(
    n: int,
    *,
    as_outputs: bool = False,
    reverse: bool = True,
) -> TaskSpanList[R] | list[R]
```

Take the top n spans from this list, sorted by their average metric value.

**Parameters:**

* **`n`**
  (`int`)
  –The number of spans to take.
* **`as_outputs`**
  (`bool`, default:
  `False`
  )
  –If True, returns a list of outputs instead of spans. Defaults to False.
* **`reverse`**
  (`bool`, default:
  `True`
  )
  –If True, sorts in descending order. Defaults to True.

**Returns:**

* `TaskSpanList[R] | list[R]`
  –A new TaskSpanList or list of outputs sorted by average metric value.

<Accordion title="Source code in dreadnode/task.py" icon="code">
```python
def top_n(
    self,
    n: int,
    *,
    as_outputs: bool = False,
    reverse: bool = True,
) -> "TaskSpanList[R] | list[R]":
    """
    Take the top n spans from this list, sorted by their average metric value.

    Args:
        n: The number of spans to take.
        as_outputs: If True, returns a list of outputs instead of spans. Defaults to False.
        reverse: If True, sorts in descending order. Defaults to True.

    Returns:
        A new TaskSpanList or list of outputs sorted by average metric value.
    """
    sorted_ = self.sorted(reverse=reverse)[:n]
    return (
        t.cast("list[R]", [span.output for span in sorted_])
        if as_outputs
        else TaskSpanList(sorted_)
    )
```


</Accordion>