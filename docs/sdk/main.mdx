---
title: dreadnode.main
---

{/*
::: dreadnode.main
*/}

Dreadnode
---------

```python
Dreadnode(
    *,
    server: str | None = None,
    token: str | None = None,
    local_dir: str | Path | Literal[False] = False,
    project: str | None = None,
    service_name: str | None = None,
    service_version: str | None = None,
    console: ConsoleOptions | Literal[False, True] = True,
    send_to_logfire: bool
    | Literal["if-token-present"] = False,
    otel_scope: str = "dreadnode",
)
```

The core Dreadnode SDK class.

A default instance of this class is created and can be used directly with `dreadnode.*`.

Otherwise, you can create your own instance and configure it with `configure()`.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def __init__(
    self,
    *,
    server: str | None = None,
    token: str | None = None,
    local_dir: str | Path | t.Literal[False] = False,
    project: str | None = None,
    service_name: str | None = None,
    service_version: str | None = None,
    console: logfire.ConsoleOptions | t.Literal[False, True] = True,
    send_to_logfire: bool | t.Literal["if-token-present"] = False,
    otel_scope: str = "dreadnode",
) -> None:
    self.server = server
    self.token = token
    self.local_dir = local_dir
    self.project = project
    self.service_name = service_name
    self.service_version = service_version
    self.console = console
    self.send_to_logfire = send_to_logfire
    self.otel_scope = otel_scope

    self._api: ApiClient | None = None

    self._logfire = logfire.DEFAULT_LOGFIRE_INSTANCE
    self._logfire.config.ignore_no_config = True

    self._fs: AbstractFileSystem = LocalFileSystem(auto_mkdir=True)
    self._fs_prefix: str = ".dreadnode/storage/"

    self._initialized = False
```


</Accordion>

### api

```python
api(
    *, server: str | None = None, token: str | None = None
) -> ApiClient
```

Get an API client based on the current configuration or the provided server and token.

If the server and token are not provided, the method will use the current configuration
and `configure()` needs to be called first.

**Parameters:**

* **`server`**
  (`str | None`, default:
  `None`
  )
  –The server URL to use for the API client.
* **`token`**
  (`str | None`, default:
  `None`
  )
  –The API token to use for authentication.

**Returns:**

* `ApiClient`
  –An ApiClient instance.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def api(self, *, server: str | None = None, token: str | None = None) -> ApiClient:
    """
    Get an API client based on the current configuration or the provided server and token.

    If the server and token are not provided, the method will use the current configuration
    and `configure()` needs to be called first.

    Args:
        server: The server URL to use for the API client.
        token: The API token to use for authentication.

    Returns:
        An ApiClient instance.
    """
    if server is not None and token is not None:
        return ApiClient(server, token)

    if not self._initialized:
        raise RuntimeError("Call .configure() before accessing the API")

    if self._api is None:
        raise RuntimeError("API is not available without a server configuration")

    return self._api
```


</Accordion>

### configure

```python
configure(
    *,
    server: str | None = None,
    token: str | None = None,
    local_dir: str | Path | Literal[False] = False,
    project: str | None = None,
    service_name: str | None = None,
    service_version: str | None = None,
    console: ConsoleOptions | Literal[False, True] = True,
    send_to_logfire: bool
    | Literal["if-token-present"] = False,
    otel_scope: str = "dreadnode",
) -> None
```

Configure the Dreadnode SDK and call `initialize()`.

This method should always be called before using the SDK.

If `server` and `token` are not provided, the SDK will look in
the associated environment variables:

* `DREADNODE_SERVER_URL` or `DREADNODE_SERVER`
* `DREADNODE_API_TOKEN` or `DREADNODE_API_KEY`

**Parameters:**

* **`server`**
  (`str | None`, default:
  `None`
  )
  –The Dreadnode server URL.
* **`token`**
  (`str | None`, default:
  `None`
  )
  –The Dreadnode API token.
* **`local_dir`**
  (`str | Path | Literal[False]`, default:
  `False`
  )
  –The local directory to store data in.
* **`project`**
  (`str | None`, default:
  `None`
  )
  –The default project name to associate all runs with.
* **`service_name`**
  (`str | None`, default:
  `None`
  )
  –The service name to use for OpenTelemetry.
* **`service_version`**
  (`str | None`, default:
  `None`
  )
  –The service version to use for OpenTelemetry.
* **`console`**
  (`ConsoleOptions | Literal[False, True]`, default:
  `True`
  )
  –Whether to log span information to the console.
* **`send_to_logfire`**
  (`bool | Literal['if-token-present']`, default:
  `False`
  )
  –Whether to send data to Logfire.
* **`otel_scope`**
  (`str`, default:
  `'dreadnode'`
  )
  –The OpenTelemetry scope name.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def configure(
    self,
    *,
    server: str | None = None,
    token: str | None = None,
    local_dir: str | Path | t.Literal[False] = False,
    project: str | None = None,
    service_name: str | None = None,
    service_version: str | None = None,
    console: logfire.ConsoleOptions | t.Literal[False, True] = True,
    send_to_logfire: bool | t.Literal["if-token-present"] = False,
    otel_scope: str = "dreadnode",
) -> None:
    """
    Configure the Dreadnode SDK and call `initialize()`.

    This method should always be called before using the SDK.

    If `server` and `token` are not provided, the SDK will look in
    the associated environment variables:

    - `DREADNODE_SERVER_URL` or `DREADNODE_SERVER`
    - `DREADNODE_API_TOKEN` or `DREADNODE_API_KEY`

    Args:
        server: The Dreadnode server URL.
        token: The Dreadnode API token.
        local_dir: The local directory to store data in.
        project: The default project name to associate all runs with.
        service_name: The service name to use for OpenTelemetry.
        service_version: The service version to use for OpenTelemetry.
        console: Whether to log span information to the console.
        send_to_logfire: Whether to send data to Logfire.
        otel_scope: The OpenTelemetry scope name.
    """

    self._initialized = False

    self.server = server or os.environ.get(ENV_SERVER_URL) or os.environ.get(ENV_SERVER)
    self.token = token or os.environ.get(ENV_API_TOKEN) or os.environ.get(ENV_API_KEY)

    if local_dir is False and ENV_LOCAL_DIR in os.environ:
        env_local_dir = os.environ.get(ENV_LOCAL_DIR)
        if env_local_dir:
            self.local_dir = Path(env_local_dir)
        else:
            self.local_dir = False
    else:
        self.local_dir = local_dir

    self.project = project or os.environ.get(ENV_PROJECT)
    self.service_name = service_name
    self.service_version = service_version
    self.console = console
    self.send_to_logfire = send_to_logfire
    self.otel_scope = otel_scope

    self.initialize()
```


</Accordion>

### continue\_run

```python
continue_run(run_context: RunContext) -> RunSpan
```

Continue a run from captured context on a remote host.

**Parameters:**

* **`run_context`**
  (`RunContext`)
  –The RunContext captured from get\_run\_context().

**Returns:**

* `RunSpan`
  –A RunSpan object that can be used as a context manager.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def continue_run(self, run_context: RunContext) -> RunSpan:
    """
    Continue a run from captured context on a remote host.

    Args:
        run_context: The RunContext captured from get_run_context().

    Returns:
        A RunSpan object that can be used as a context manager.
    """
    if not self._initialized:
        self.initialize()

    return RunSpan.from_context(
        context=run_context,
        tracer=self._get_tracer(),
        file_system=self._fs,
        prefix_path=self._fs_prefix,
    )
```


</Accordion>

### get\_run\_context

```python
get_run_context() -> RunContext
```

Capture the current run context for transfer to another host, thread, or process.

Use `continue_run()` to continue the run anywhere else.

**Returns:**

* `RunContext`
  –RunContext containing run state and trace propagation headers.

**Raises:**

* `RuntimeError`
  –If called outside of an active run.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def get_run_context(self) -> RunContext:
    """
    Capture the current run context for transfer to another host, thread, or process.

    Use `continue_run()` to continue the run anywhere else.

    Returns:
        RunContext containing run state and trace propagation headers.

    Raises:
        RuntimeError: If called outside of an active run.
    """
    if (run := current_run_span.get()) is None:
        raise RuntimeError("get_run_context() must be called within a run")

    # Capture OpenTelemetry trace context
    trace_context: dict[str, str] = {}
    propagate.inject(trace_context)

    return {
        "run_id": run.run_id,
        "run_name": run.name,
        "project": run.project,
        "trace_context": trace_context,
    }
```


</Accordion>

### initialize

```python
initialize() -> None
```

Initialize the Dreadnode SDK.

This method is called automatically when you call `configure()`.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def initialize(self) -> None:
    """
    Initialize the Dreadnode SDK.

    This method is called automatically when you call `configure()`.
    """
    if self._initialized:
        return

    span_processors: list[SpanProcessor] = []
    metric_readers: list[MetricReader] = []

    self.server = self.server or (DEFAULT_SERVER_URL if self.token else None)
    if not (self.server or self.token or self.local_dir):
        warn_at_user_stacklevel(
            "Your current configuration won't persist run data anywhere. "
            "Use `dreadnode.init(server=..., token=...)`, `dreadnode.init(local_dir=...)`, "
            f"or use environment variables ({ENV_SERVER_URL}, {ENV_API_TOKEN}, {ENV_LOCAL_DIR}).",
            category=DreadnodeConfigWarning,
        )

    if self.local_dir:
        config = FileExportConfig(
            base_path=self.local_dir,
            prefix=self.project + "-" if self.project else "",
        )
        span_processors.append(BatchSpanProcessor(FileSpanExporter(config)))
        metric_readers.append(FileMetricReader(config))

    if self.token and self.server:
        try:
            parsed_url = urlparse(self.server)
            if not parsed_url.scheme:
                netloc = parsed_url.path.split("/")[0]
                path = "/".join(parsed_url.path.split("/")[1:])
                parsed_new = parsed_url._replace(
                    scheme="https", netloc=netloc, path=f"/{path}" if path else ""
                )
                self.server = urlunparse(parsed_new)

            self._api = ApiClient(self.server, self.token)

            self._api.list_projects()
        except Exception as e:
            raise RuntimeError(
                f"Failed to connect to the Dreadnode server: {e}",
            ) from e

        headers = {"User-Agent": f"dreadnode/{VERSION}", "X-Api-Key": self.token}
        span_processors.append(
            BatchSpanProcessor(
                RemovePendingSpansExporter(  # This will tell Logfire to emit pending spans to us as well
                    OTLPSpanExporter(
                        endpoint=urljoin(self.server, "/api/otel/traces"),
                        headers=headers,
                        compression=Compression.Gzip,
                    ),
                ),
            ),
        )
        # TODO(nick): Metrics
        # https://linear.app/dreadnode/issue/ENG-1310/sdk-add-metrics-exports
        # metric_readers.append(
        #     PeriodicExportingMetricReader(
        #         OTLPMetricExporter(
        #             endpoint=urljoin(self.server, "/v1/metrics"),
        #             headers=headers,
        #             compression=Compression.Gzip,
        #             # preferred_temporality
        #         )
        #     )
        # )

        credentials = self._api.get_user_data_credentials()
        self._fs = S3FileSystem(
            key=credentials.access_key_id,
            secret=credentials.secret_access_key,
            token=credentials.session_token,
            client_kwargs={
                "endpoint_url": credentials.endpoint,
                "region_name": credentials.region,
            },
        )
        self._fs_prefix = f"{credentials.bucket}/{credentials.prefix}/"

    self._logfire = logfire.configure(
        local=not self.is_default,
        send_to_logfire=self.send_to_logfire,
        additional_span_processors=span_processors,
        metrics=logfire.MetricsOptions(additional_readers=metric_readers),
        service_name=self.service_name,
        service_version=self.service_version,
        console=logfire.ConsoleOptions() if self.console is True else self.console,
        scrubbing=False,
        inspect_arguments=False,
        distributed_tracing=False,
    )
    self._logfire.config.ignore_no_config = True

    self._initialized = True
```


</Accordion>

### link\_objects

```python
link_objects(
    origin: Any, link: Any, **attributes: JsonValue
) -> None
```

Associate two runtime objects with each other.

This is useful for linking any two objects which are related to
each other, such as a model and its training data, or an input
prompt and the resulting output.

Example

```python
with dreadnode.run("my_run") as run:
    model = SomeModel()
    data = SomeData()

    run.link_objects(model, data)
```

**Parameters:**

* **`origin`**
  (`Any`)
  –The origin object to link from.
* **`link`**
  (`Any`)
  –The linked object to link to.
* **`**attributes`**
  (`JsonValue`, default:
  `{}`
  )
  –Additional attributes to attach to the link.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def link_objects(self, origin: t.Any, link: t.Any, **attributes: JsonValue) -> None:
    """
    Associate two runtime objects with each other.

    This is useful for linking any two objects which are related to
    each other, such as a model and its training data, or an input
    prompt and the resulting output.

    Example:
        ~~~
        with dreadnode.run("my_run") as run:
            model = SomeModel()
            data = SomeData()

            run.link_objects(model, data)
        ~~~

    Args:
        origin: The origin object to link from.
        link: The linked object to link to.
        **attributes: Additional attributes to attach to the link.
    """
    if (run := current_run_span.get()) is None:
        raise RuntimeError("link() must be called within a run")

    origin_hash = run.log_object(origin)
    link_hash = run.log_object(link)
    run.link_objects(origin_hash, link_hash, **attributes)
```


</Accordion>

### log\_artifact

```python
log_artifact(local_uri: str | Path) -> None
```

Log a file or directory artifact to the current run.

This method uploads a local file or directory to the artifact storage associated with the run.

**Examples:**

Log a single file:

```python
with dreadnode.run("my_run") as run:
    # Save a file
    with open("results.json", "w") as f:
        json.dump(results, f)

    # Log it as an artifact
    run.log_artifact("results.json")
```

Log a directory:

```python
with dreadnode.run("my_run") as run:
    # Create a directory with model files
    os.makedirs("model_output", exist_ok=True)
    save_model("model_output/model.pkl")
    save_config("model_output/config.yaml")

    # Log the entire directory as an artifact
    run.log_artifact("model_output")
```

**Parameters:**

* **`local_uri`**
  (`str | Path`)
  –The local path to the file to upload.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_artifact(
    self,
    local_uri: str | Path,
) -> None:
    """
    Log a file or directory artifact to the current run.

    This method uploads a local file or directory to the artifact storage associated with the run.

    Examples:
        Log a single file:
        ~~~
        with dreadnode.run("my_run") as run:
            # Save a file
            with open("results.json", "w") as f:
                json.dump(results, f)

            # Log it as an artifact
            run.log_artifact("results.json")
        ~~~

        Log a directory:
        ~~~
        with dreadnode.run("my_run") as run:
            # Create a directory with model files
            os.makedirs("model_output", exist_ok=True)
            save_model("model_output/model.pkl")
            save_config("model_output/config.yaml")

            # Log the entire directory as an artifact
            run.log_artifact("model_output")
        ~~~

    Args:
        local_uri: The local path to the file to upload.
    """
    if (run := current_run_span.get()) is None:
        raise RuntimeError("log_artifact() must be called within a run")

    run.log_artifact(local_uri=local_uri)
```


</Accordion>

### log\_input

```python
log_input(
    name: str,
    value: Any,
    *,
    label: str | None = None,
    to: ToObject = "task-or-run",
    **attributes: Any,
) -> None
```

Log a single input to the current task or run.

Inputs can be any runtime object, which are serialized, stored, and tracked
in the Dreadnode UI.

Example

```python
@dreadnode.task
async def my_task(x: int) -> int:
    dreadnode.log_input("input_name", x)
    return x * 2

with dreadnode.run("my_run"):
    dreadnode.log_input("input_name", some_dataframe)

    await my_task(2)
```


<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_input(
    self,
    name: str,
    value: t.Any,
    *,
    label: str | None = None,
    to: ToObject = "task-or-run",
    **attributes: t.Any,
) -> None:
    """
    Log a single input to the current task or run.

    Inputs can be any runtime object, which are serialized, stored, and tracked
    in the Dreadnode UI.

    Example:
        ~~~
        @dreadnode.task
        async def my_task(x: int) -> int:
            dreadnode.log_input("input_name", x)
            return x * 2

        with dreadnode.run("my_run"):
            dreadnode.log_input("input_name", some_dataframe)

            await my_task(2)
        ~~~
    """
    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError("log_inputs() must be called within a run")

    target.log_input(name, value, label=label, **attributes)
```


</Accordion>

### log\_inputs

```python
log_inputs(
    to: ToObject = "task-or-run", **inputs: JsonValue
) -> None
```

Log multiple inputs to the current task or run.

See `log_input()` for more details.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_inputs(
    self,
    to: ToObject = "task-or-run",
    **inputs: JsonValue,
) -> None:
    """
    Log multiple inputs to the current task or run.

    See `log_input()` for more details.
    """
    for name, value in inputs.items():
        self.log_input(name, value, to=to)
```


</Accordion>

### log\_metric

```python
log_metric(
    name: str,
    value: float | bool,
    *,
    step: int = 0,
    origin: Any | None = None,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> Metric
```

```python
log_metric(
    name: str,
    value: Metric,
    *,
    origin: Any | None = None,
    mode: MetricAggMode | None = None,
    to: ToObject = "task-or-run",
) -> Metric
```

```python
log_metric(
    name: str,
    value: float | bool | Metric,
    *,
    step: int = 0,
    origin: Any | None = None,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> Metric
```

Log a single metric to the current task or run.

Metrics are some measurement or recorded value related to the task or run.
They can be used to track performance, resource usage, or other quantitative data.

**Examples:**

With a raw value:

```python
with dreadnode.run("my_run") as run:
    run.log_metric("accuracy", 0.95, step=10)
    run.log_metric("loss", 0.05, step=10, mode="min")
```

With a Metric object:

```python
with dreadnode.run("my_run") as run:
    metric = Metric(0.95, step=10, timestamp=datetime.now(timezone.utc))
    run.log_metric("accuracy", metric)
```

**Parameters:**

* **`name`**
  (`str`)
  –The name of the metric.
* **`value`**
  (`float | bool | Metric`)
  –The value of the metric, either as a raw float/bool or a Metric object.
* **`step`**
  (`int`, default:
  `0`
  )
  –The step of the metric.
* **`origin`**
  (`Any | None`, default:
  `None`
  )
  –The origin of the metric - can be provided any object which was logged
  as an input or output anywhere in the run.
* **`timestamp`**
  (`datetime | None`, default:
  `None`
  )
  –The timestamp of the metric - defaults to the current time.
* **`mode`**
  (`MetricAggMode | None`, default:
  `None`
  )
  –The aggregation mode to use for the metric. Helpful when you want to let
  the library take care of translating your raw values into better representations.
  - direct: do not modify the value at all (default)
  - min: the lowest observed value reported for this metric
  - max: the highest observed value reported for this metric
  - avg: the average of all reported values for this metric
  - sum: the cumulative sum of all reported values for this metric
  - count: increment every time this metric is logged - disregard value
* **`attributes`**
  (`JsonDict | None`, default:
  `None`
  )
  –A dictionary of additional attributes to attach to the metric.
* **`to`**
  (`ToObject`, default:
  `'task-or-run'`
  )
  –The target object to log the metric to. Can be "task-or-run" or "run".
  Defaults to "task-or-run". If "task-or-run", the metric will be logged
  to the current task or run, whichever is the nearest ancestor.

**Returns:**

* `Metric`
  –The logged metric object.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_metric(
    self,
    name: str,
    value: float | bool | Metric,
    *,
    step: int = 0,
    origin: t.Any | None = None,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> Metric:
    """
    Log a single metric to the current task or run.

    Metrics are some measurement or recorded value related to the task or run.
    They can be used to track performance, resource usage, or other quantitative data.

    Examples:
        With a raw value:
        ~~~
        with dreadnode.run("my_run") as run:
            run.log_metric("accuracy", 0.95, step=10)
            run.log_metric("loss", 0.05, step=10, mode="min")
        ~~~

        With a Metric object:
        ~~~
        with dreadnode.run("my_run") as run:
            metric = Metric(0.95, step=10, timestamp=datetime.now(timezone.utc))
            run.log_metric("accuracy", metric)
        ~~~

    Args:
        name: The name of the metric.
        value: The value of the metric, either as a raw float/bool or a Metric object.
        step: The step of the metric.
        origin: The origin of the metric - can be provided any object which was logged
            as an input or output anywhere in the run.
        timestamp: The timestamp of the metric - defaults to the current time.
        mode: The aggregation mode to use for the metric. Helpful when you want to let
            the library take care of translating your raw values into better representations.
            - direct: do not modify the value at all (default)
            - min: the lowest observed value reported for this metric
            - max: the highest observed value reported for this metric
            - avg: the average of all reported values for this metric
            - sum: the cumulative sum of all reported values for this metric
            - count: increment every time this metric is logged - disregard value
        attributes: A dictionary of additional attributes to attach to the metric.
        to: The target object to log the metric to. Can be "task-or-run" or "run".
            Defaults to "task-or-run". If "task-or-run", the metric will be logged
            to the current task or run, whichever is the nearest ancestor.

    Returns:
        The logged metric object.
    """
    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError("log_metric() must be called within a run")

    metric = (
        value
        if isinstance(value, Metric)
        else Metric(
            float(value), step, timestamp or datetime.now(timezone.utc), attributes or {}
        )
    )
    return target.log_metric(name, metric, origin=origin, mode=mode)
```


</Accordion>

### log\_metrics

```python
log_metrics(
    metrics: dict[str, float | bool],
    *,
    step: int = 0,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> list[Metric]
```

```python
log_metrics(
    metrics: list[MetricDict],
    *,
    step: int = 0,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> list[Metric]
```

```python
log_metrics(
    metrics: dict[str, float | bool] | list[MetricDict],
    *,
    step: int = 0,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> list[Metric]
```

Log multiple metrics to the current task or run.

**Examples:**

Log metrics from a dictionary:

```python
dreadnode.log_metrics(
    {
        "accuracy": 0.95,
        "loss": 0.05,
        "f1_score": 0.92
    },
    step=10
)
```

Log metrics from a list of MetricDicts:

```python
dreadnode.log_metrics(
    [
        {"name": "accuracy", "value": 0.95},
        {"name": "loss", "value": 0.05, "mode": "min"}
    ],
    step=10
)
```

**Parameters:**

* **`metrics`**
  (`dict[str, float | bool] | list[MetricDict]`)
  –Either a dictionary of name/value pairs or a list of MetricDicts to log.
* **`step`**
  (`int`, default:
  `0`
  )
  –Default step value for metrics if not supplied.
* **`timestamp`**
  (`datetime | None`, default:
  `None`
  )
  –Default timestamp for metrics if not supplied.
* **`mode`**
  (`MetricAggMode | None`, default:
  `None`
  )
  –Default aggregation mode for metrics if not supplied.
* **`attributes`**
  (`JsonDict | None`, default:
  `None`
  )
  –Default attributes for metrics if not supplied.
* **`to`**
  (`ToObject`, default:
  `'task-or-run'`
  )
  –The target object to log metrics to. Can be "task-or-run" or "run".
  Defaults to "task-or-run". If "task-or-run", the metrics will be logged
  to the current task or run, whichever is the nearest ancestor.

**Returns:**

* `list[Metric]`
  –List of logged Metric objects.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_metrics(
    self,
    metrics: dict[str, float | bool] | list[MetricDict],
    *,
    step: int = 0,
    timestamp: datetime | None = None,
    mode: MetricAggMode | None = None,
    attributes: JsonDict | None = None,
    to: ToObject = "task-or-run",
) -> list[Metric]:
    """
    Log multiple metrics to the current task or run.

    Examples:
        Log metrics from a dictionary:
        ~~~
        dreadnode.log_metrics(
            {
                "accuracy": 0.95,
                "loss": 0.05,
                "f1_score": 0.92
            },
            step=10
        )
        ~~~

        Log metrics from a list of MetricDicts:
        ~~~
        dreadnode.log_metrics(
            [
                {"name": "accuracy", "value": 0.95},
                {"name": "loss", "value": 0.05, "mode": "min"}
            ],
            step=10
        )
        ~~~

    Args:
        metrics: Either a dictionary of name/value pairs or a list of MetricDicts to log.
        step: Default step value for metrics if not supplied.
        timestamp: Default timestamp for metrics if not supplied.
        mode: Default aggregation mode for metrics if not supplied.
        attributes: Default attributes for metrics if not supplied.
        to: The target object to log metrics to. Can be "task-or-run" or "run".
            Defaults to "task-or-run". If "task-or-run", the metrics will be logged
            to the current task or run, whichever is the nearest ancestor.

    Returns:
        List of logged Metric objects.
    """

    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError("log_metrics() must be called within a run")

    logged_metrics: list[Metric] = []

    # Dictionary of name/value pairs
    if isinstance(metrics, dict):
        logged_metrics = [
            target.log_metric(
                name,
                value,
                step=step,
                timestamp=timestamp,
                mode=mode,
                attributes=attributes,
            )
            for name, value in metrics.items()
        ]

    # List of MetricDicts
    else:
        logged_metrics = [
            target.log_metric(
                metric["name"],
                metric["value"],
                step=metric.get("step", step),
                timestamp=metric.get("timestamp", timestamp),
                mode=metric.get("mode", mode),
                attributes=metric.get("attributes", attributes) or {},
            )
            for metric in metrics
        ]

    return logged_metrics
```


</Accordion>

### log\_output

```python
log_output(
    name: str,
    value: Any,
    *,
    label: str | None = None,
    to: ToObject = "task-or-run",
    **attributes: JsonValue,
) -> None
```

Log a single output to the current task or run.

Outputs can be any runtime object, which are serialized, stored, and tracked
in the Dreadnode UI.

Example

```python
@dreadnode.task
async def my_task(x: int) -> int:
    result = x * 2
    dreadnode.log_output("result", x * 2)
    return result

with dreadnode.run("my_run"):
    await my_task(2)

    dreadnode.log_output("other", 123)
```


<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_output(
    self,
    name: str,
    value: t.Any,
    *,
    label: str | None = None,
    to: ToObject = "task-or-run",
    **attributes: JsonValue,
) -> None:
    """
    Log a single output to the current task or run.

    Outputs can be any runtime object, which are serialized, stored, and tracked
    in the Dreadnode UI.

    Example:
        ~~~
        @dreadnode.task
        async def my_task(x: int) -> int:
            result = x * 2
            dreadnode.log_output("result", x * 2)
            return result

        with dreadnode.run("my_run"):
            await my_task(2)

            dreadnode.log_output("other", 123)
        ~~~
    """
    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError(
            "log_output() must be called within a run or a task",
        )

    target.log_output(name, value, label=label, **attributes)
```


</Accordion>

### log\_outputs

```python
log_outputs(
    to: ToObject = "task-or-run", **outputs: JsonValue
) -> None
```

Log multiple outputs to the current task or run.

See `log_output()` for more details.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_outputs(
    self,
    to: ToObject = "task-or-run",
    **outputs: JsonValue,
) -> None:
    """
    Log multiple outputs to the current task or run.

    See `log_output()` for more details.
    """
    for name, value in outputs.items():
        self.log_output(name, value, to=to)
```


</Accordion>

### log\_param

```python
log_param(
    key: str,
    value: JsonValue,
    *,
    to: ToObject = "task-or-run",
) -> None
```

Log a single parameter to the current task or run.

Parameters are key-value pairs that are associated with the task or run
and can be used to track configuration values, hyperparameters, or other
metadata.

Example

```python
with dreadnode.run("my_run") as run:
    run.log_param("param_name", "param_value")
```

**Parameters:**

* **`key`**
  (`str`)
  –The name of the parameter.
* **`value`**
  (`JsonValue`)
  –The value of the parameter.
* **`to`**
  (`ToObject`, default:
  `'task-or-run'`
  )
  –The target object to log the parameter to. Can be "task-or-run" or "run".
  Defaults to "task-or-run". If "task-or-run", the parameter will be logged
  to the current task or run, whichever is the nearest ancestor.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_param(
    self,
    key: str,
    value: JsonValue,
    *,
    to: ToObject = "task-or-run",
) -> None:
    """
    Log a single parameter to the current task or run.

    Parameters are key-value pairs that are associated with the task or run
    and can be used to track configuration values, hyperparameters, or other
    metadata.

    Example:
        ~~~
        with dreadnode.run("my_run") as run:
            run.log_param("param_name", "param_value")
        ~~~

    Args:
        key: The name of the parameter.
        value: The value of the parameter.
        to: The target object to log the parameter to. Can be "task-or-run" or "run".
            Defaults to "task-or-run". If "task-or-run", the parameter will be logged
            to the current task or run, whichever is the nearest ancestor.
    """
    self.log_params(to=to, **{key: value})
```


</Accordion>

### log\_params

```python
log_params(
    to: ToObject = "run", **params: JsonValue
) -> None
```

Log multiple parameters to the current task or run.

Parameters are key-value pairs that are associated with the task or run
and can be used to track configuration values, hyperparameters, or other
metadata.

Example

```python
with dreadnode.run("my_run") as run:
    run.log_params(
        param1="value1",
        param2="value2"
    )
```

**Parameters:**

* **`to`**
  (`ToObject`, default:
  `'run'`
  )
  –The target object to log the parameters to. Can be "task-or-run" or "run".
  Defaults to "task-or-run". If "task-or-run", the parameters will be logged
  to the current task or run, whichever is the nearest ancestor.
* **`**params`**
  (`JsonValue`, default:
  `{}`
  )
  –The parameters to log. Each parameter is a key-value pair.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def log_params(self, to: ToObject = "run", **params: JsonValue) -> None:
    """
    Log multiple parameters to the current task or run.

    Parameters are key-value pairs that are associated with the task or run
    and can be used to track configuration values, hyperparameters, or other
    metadata.

    Example:
        ~~~
        with dreadnode.run("my_run") as run:
            run.log_params(
                param1="value1",
                param2="value2"
            )
        ~~~

    Args:
        to: The target object to log the parameters to. Can be "task-or-run" or "run".
            Defaults to "task-or-run". If "task-or-run", the parameters will be logged
            to the current task or run, whichever is the nearest ancestor.
        **params: The parameters to log. Each parameter is a key-value pair.
    """
    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError("log_params() must be called within a run")

    target.log_params(**params)
```


</Accordion>

### push\_update

```python
push_update() -> None
```

Push any pending run data to the server before run completion.

This is useful for ensuring that the UI is up to date with the
latest data. Data is automatically pushed periodically, but
you can call this method to force a push.

Example

```
with dreadnode.run("my\_run"):
dreadnode.log\_params(...)
dreadnode.log\_metric(...)
dreadnode.push\_update()

```python
# do more work
```


<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def push_update(self) -> None:
    """
    Push any pending run data to the server before run completion.

    This is useful for ensuring that the UI is up to date with the
    latest data. Data is automatically pushed periodically, but
    you can call this method to force a push.

    Example:
        ~~~
        with dreadnode.run("my_run"):
            dreadnode.log_params(...)
            dreadnode.log_metric(...)
            dreadnode.push_update()

            # do more work
    """
    if (run := current_run_span.get()) is None:
        raise RuntimeError("Run updates must be pushed within a run")

    run.push_update(force=True)
```


</Accordion>

### run

```python
run(
    name: str | None = None,
    *,
    tags: Sequence[str] | None = None,
    params: AnyDict | None = None,
    project: str | None = None,
    autolog: bool = True,
    **attributes: Any,
) -> RunSpan
```

Create a new run.

Runs are the main way to track work in Dreadnode. They are
associated with a specific project and can have parameters,
inputs, and outputs logged to them.

You cannot create runs inside other runs.

Example

```python
with dreadnode.run("my_run"):
    # do some work here
    pass
```

**Parameters:**

* **`name`**
  (`str | None`, default:
  `None`
  )
  –The name of the run. If not provided, a random name will be generated.
* **`tags`**
  (`Sequence[str] | None`, default:
  `None`
  )
  –A list of tags to attach to the run.
* **`params`**
  (`AnyDict | None`, default:
  `None`
  )
  –A dictionary of parameters to attach to the run.
* **`project`**
  (`str | None`, default:
  `None`
  )
  –The project name to associate the run with. If not provided,
  the project passed to `configure()` will be used, or the
  run will be associated with a default project.
* **`autolog`**
  (`bool`, default:
  `True`
  )
  –Whether to automatically log task inputs, outputs, and execution metrics if unspecified.
* **`**attributes`**
  (`Any`, default:
  `{}`
  )
  –Additional attributes to attach to the run span.

**Returns:**

* `RunSpan`
  –A RunSpan object that can be used as a context manager.
* `RunSpan`
  –The run will automatically be completed when the context manager exits.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def run(
    self,
    name: str | None = None,
    *,
    tags: t.Sequence[str] | None = None,
    params: AnyDict | None = None,
    project: str | None = None,
    autolog: bool = True,
    **attributes: t.Any,
) -> RunSpan:
    """
    Create a new run.

    Runs are the main way to track work in Dreadnode. They are
    associated with a specific project and can have parameters,
    inputs, and outputs logged to them.

    You cannot create runs inside other runs.

    Example:
        ~~~
        with dreadnode.run("my_run"):
            # do some work here
            pass
        ~~~

    Args:
        name: The name of the run. If not provided, a random name will be generated.
        tags: A list of tags to attach to the run.
        params: A dictionary of parameters to attach to the run.
        project: The project name to associate the run with. If not provided,
            the project passed to `configure()` will be used, or the
            run will be associated with a default project.
        autolog: Whether to automatically log task inputs, outputs, and execution metrics if unspecified.
        **attributes: Additional attributes to attach to the run span.

    Returns:
        A RunSpan object that can be used as a context manager.
        The run will automatically be completed when the context manager exits.
    """
    if not self._initialized:
        self.initialize()

    if name is None:
        name = f"{coolname.generate_slug(2)}-{random.randint(100, 999)}"  # noqa: S311 # nosec

    return RunSpan(
        name=name,
        project=project or self.project or "default",
        attributes=attributes,
        tracer=self._get_tracer(),
        params=params,
        tags=tags,
        file_system=self._fs,
        prefix_path=self._fs_prefix,
        autolog=autolog,
    )
```


</Accordion>

### scorer

```python
scorer(
    *,
    name: str | None = None,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> t.Callable[[ScorerCallable[T]], Scorer[T]]
```

Make a scorer from a callable function.

This is useful when you want to change the name of the scorer
or add additional attributes to it.

Example

```python
@dreadnode.scorer(name="my_scorer")
async def my_scorer(x: int) -> float:
    return x * 2

@dreadnode.task(scorers=[my_scorer])
async def my_task(x: int) -> int:
    return x * 2

await my_task(2)
```

**Parameters:**

* **`name`**
  (`str | None`, default:
  `None`
  )
  –The name of the scorer.
* **`tags`**
  (`Sequence[str] | None`, default:
  `None`
  )
  –A list of tags to attach to the scorer.
* **`**attributes`**
  (`Any`, default:
  `{}`
  )
  –A dictionary of attributes to attach to the scorer.

**Returns:**

* `Callable[[ScorerCallable[T]], Scorer[T]]`
  –A new Scorer object.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def scorer(
    self,
    *,
    name: str | None = None,
    tags: t.Sequence[str] | None = None,
    **attributes: t.Any,
) -> t.Callable[[ScorerCallable[T]], Scorer[T]]:
    """
    Make a scorer from a callable function.

    This is useful when you want to change the name of the scorer
    or add additional attributes to it.

    Example:
        ~~~
        @dreadnode.scorer(name="my_scorer")
        async def my_scorer(x: int) -> float:
            return x * 2

        @dreadnode.task(scorers=[my_scorer])
        async def my_task(x: int) -> int:
            return x * 2

        await my_task(2)
        ~~~

    Args:
        name: The name of the scorer.
        tags: A list of tags to attach to the scorer.
        **attributes: A dictionary of attributes to attach to the scorer.

    Returns:
        A new Scorer object.
    """

    def make_scorer(func: ScorerCallable[T]) -> Scorer[T]:
        return Scorer.from_callable(
            self._get_tracer(),
            func,
            name=name,
            tags=tags,
            attributes=attributes,
        )

    return make_scorer
```


</Accordion>

### shutdown

```python
shutdown() -> None
```

Shutdown any associate OpenTelemetry components and flush any pending spans.

It is not required to call this method, as the SDK will automatically
flush and shutdown when the process exits.

However, if you want to ensure that all spans are flushed before
exiting, you can call this method manually.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
@handle_internal_errors()
def shutdown(self) -> None:
    """
    Shutdown any associate OpenTelemetry components and flush any pending spans.

    It is not required to call this method, as the SDK will automatically
    flush and shutdown when the process exits.

    However, if you want to ensure that all spans are flushed before
    exiting, you can call this method manually.
    """
    if not self._initialized:
        return

    self._logfire.shutdown()
```


</Accordion>

### span

```python
span(
    name: str,
    *,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> Span
```

Create a new OpenTelemety span.

Spans are more lightweight than tasks, but still let you track
work being performed and view it in the UI. You cannot
log parameters, inputs, or outputs to spans.

Example

```python
with dreadnode.span("my_span") as span:
    # do some work here
    pass
```

**Parameters:**

* **`name`**
  (`str`)
  –The name of the span.
* **`tags`**
  (`Sequence[str] | None`, default:
  `None`
  )
  –A list of tags to attach to the span.
* **`**attributes`**
  (`Any`, default:
  `{}`
  )
  –A dictionary of attributes to attach to the span.

**Returns:**

* `Span`
  –A Span object.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def span(
    self,
    name: str,
    *,
    tags: t.Sequence[str] | None = None,
    **attributes: t.Any,
) -> Span:
    """
    Create a new OpenTelemety span.

    Spans are more lightweight than tasks, but still let you track
    work being performed and view it in the UI. You cannot
    log parameters, inputs, or outputs to spans.

    Example:
        ~~~
        with dreadnode.span("my_span") as span:
            # do some work here
            pass
        ~~~

    Args:
        name: The name of the span.
        tags: A list of tags to attach to the span.
        **attributes: A dictionary of attributes to attach to the span.

    Returns:
        A Span object.
    """
    return Span(
        name=name,
        attributes=attributes,
        tracer=self._get_tracer(),
        tags=tags,
    )
```


</Accordion>

### tag

```python
tag(*tag: str, to: ToObject = 'task-or-run') -> None
```

Add one or many tags to the current task or run.

Example

```python
with dreadnode.run("my_run") as run:
    run.tag("my_tag")
```

**Parameters:**

* **`tag`**
  (`str`, default:
  `()`
  )
  –The tag to attach to the task or run.
* **`to`**
  (`ToObject`, default:
  `'task-or-run'`
  )
  –The target object to log the tag to. Can be "task-or-run" or "run".
  Defaults to "task-or-run". If "task-or-run", the tag will be logged
  to the current task or run, whichever is the nearest ancestor.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def tag(self, *tag: str, to: ToObject = "task-or-run") -> None:
    """
    Add one or many tags to the current task or run.

    Example:
        ~~~
        with dreadnode.run("my_run") as run:
            run.tag("my_tag")
        ~~~

    Args:
        tag: The tag to attach to the task or run.
        to: The target object to log the tag to. Can be "task-or-run" or "run".
            Defaults to "task-or-run". If "task-or-run", the tag will be logged
            to the current task or run, whichever is the nearest ancestor.
    """
    task = current_task_span.get()
    run = current_run_span.get()

    target = (task or run) if to == "task-or-run" else run
    if target is None:
        raise RuntimeError("Tagging must be done within a run")

    target.add_tags(tag)
```


</Accordion>

### task

```python
task(
    *,
    scorers: None = None,
    name: str | None = None,
    label: str | None = None,
    log_params: Sequence[str] | bool = False,
    log_inputs: Sequence[str]
    | bool
    | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> TaskDecorator
```

```python
task(
    *,
    scorers: Sequence[Scorer[R] | ScorerCallable[R]],
    name: str | None = None,
    label: str | None = None,
    log_params: Sequence[str] | bool = False,
    log_inputs: Sequence[str]
    | bool
    | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> ScoredTaskDecorator[R]
```

```python
task(
    *,
    scorers: Sequence[Scorer[Any] | ScorerCallable[Any]]
    | None = None,
    name: str | None = None,
    label: str | None = None,
    log_params: Sequence[str] | bool = False,
    log_inputs: Sequence[str]
    | bool
    | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> TaskDecorator
```

Create a new task from a function.

Example

```python
@dreadnode.task(name="my_task")
async def my_task(x: int) -> int:
    return x * 2

await my_task(2)
```

**Parameters:**

* **`scorers`**
  (`Sequence[Scorer[Any] | ScorerCallable[Any]] | None`, default:
  `None`
  )
  –A list of scorers to attach to the task. These will be called after every execution
  of the task and will be passed the task's output.
* **`name`**
  (`str | None`, default:
  `None`
  )
  –The name of the task.
* **`label`**
  (`str | None`, default:
  `None`
  )
  –The label of the task - useful for filtering in the UI.
* **`log_params`**
  (`Sequence[str] | bool`, default:
  `False`
  )
  –Whether to log all, or specific, incoming arguments to the function as parameters.
* **`log_inputs`**
  (`Sequence[str] | bool | Inherited`, default:
  `INHERITED`
  )
  –Whether to log all, or specific, incoming arguments to the function as inputs.
* **`log_output`**
  (`bool | Inherited`, default:
  `INHERITED`
  )
  –Whether to log the result of the function as an output.
* **`tags`**
  (`Sequence[str] | None`, default:
  `None`
  )
  –A list of tags to attach to the task span.
* **`**attributes`**
  (`Any`, default:
  `{}`
  )
  –A dictionary of attributes to attach to the task span.

**Returns:**

* `TaskDecorator`
  –A new Task object.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def task(
    self,
    *,
    scorers: t.Sequence[Scorer[t.Any] | ScorerCallable[t.Any]] | None = None,
    name: str | None = None,
    label: str | None = None,
    log_params: t.Sequence[str] | bool = False,
    log_inputs: t.Sequence[str] | bool | Inherited = INHERITED,
    log_output: bool | Inherited = INHERITED,
    tags: t.Sequence[str] | None = None,
    **attributes: t.Any,
) -> TaskDecorator:
    """
    Create a new task from a function.

    Example:
        ~~~
        @dreadnode.task(name="my_task")
        async def my_task(x: int) -> int:
            return x * 2

        await my_task(2)
        ~~~

    Args:
        scorers: A list of scorers to attach to the task. These will be called after every execution
            of the task and will be passed the task's output.
        name: The name of the task.
        label: The label of the task - useful for filtering in the UI.
        log_params: Whether to log all, or specific, incoming arguments to the function as parameters.
        log_inputs: Whether to log all, or specific, incoming arguments to the function as inputs.
        log_output: Whether to log the result of the function as an output.
        tags: A list of tags to attach to the task span.
        **attributes: A dictionary of attributes to attach to the task span.

    Returns:
        A new Task object.
    """

    def make_task(
        func: t.Callable[P, t.Awaitable[R]] | t.Callable[P, R],
    ) -> Task[P, R]:
        unwrapped = inspect.unwrap(func)

        if inspect.isgeneratorfunction(unwrapped) or inspect.isasyncgenfunction(
            unwrapped,
        ):
            raise TypeError("@task cannot be applied to generators")

        func_name = getattr(
            unwrapped,
            "__qualname__",
            getattr(func, "__name__", safe_repr(func)),
        )

        _name = name or func_name
        _label = label or func_name

        # conform our label for sanity
        _label = clean_str(_label)

        _attributes = attributes or {}
        _attributes["code.function"] = func_name
        with contextlib.suppress(Exception):
            _attributes["code.lineno"] = unwrapped.__code__.co_firstlineno
        with contextlib.suppress(Exception):
            _attributes.update(
                get_filepath_attribute(
                    inspect.getsourcefile(unwrapped),  # type: ignore [arg-type]
                ),
            )

        return Task(
            tracer=self._get_tracer(),
            name=_name,
            attributes=_attributes,
            func=t.cast("t.Callable[P, R]", func),
            scorers=[
                scorer
                if isinstance(scorer, Scorer)
                else Scorer.from_callable(self._get_tracer(), scorer)
                for scorer in scorers or []
            ],
            tags=list(tags or []),
            log_params=log_params,
            log_inputs=log_inputs,
            log_output=log_output,
            label=_label,
        )

    return make_task
```


</Accordion>

### task\_span

```python
task_span(
    name: str,
    *,
    label: str | None = None,
    params: AnyDict | None = None,
    tags: Sequence[str] | None = None,
    **attributes: Any,
) -> TaskSpan[t.Any]
```

Create a task span without an explicit associated function.

This is useful for creating tasks on the fly without having to
define a function.

Example

```python
async with dreadnode.task_span("my_task") as task:
    # do some work here
    pass
```

Args:
name: The name of the task.
label: The label of the task - useful for filtering in the UI.
params: A dictionary of parameters to attach to the task span.
tags: A list of tags to attach to the task span.
\*\*attributes: A dictionary of attributes to attach to the task span.

**Returns:**

* `TaskSpan[Any]`
  –A TaskSpan object.

<Accordion title="Source code in dreadnode/main.py" icon="code">
```python
def task_span(
    self,
    name: str,
    *,
    label: str | None = None,
    params: AnyDict | None = None,
    tags: t.Sequence[str] | None = None,
    **attributes: t.Any,
) -> TaskSpan[t.Any]:
    """
    Create a task span without an explicit associated function.

    This is useful for creating tasks on the fly without having to
    define a function.

    Example:
        ~~~
        async with dreadnode.task_span("my_task") as task:
            # do some work here
            pass
        ~~~
    Args:
        name: The name of the task.
        label: The label of the task - useful for filtering in the UI.
        params: A dictionary of parameters to attach to the task span.
        tags: A list of tags to attach to the task span.
        **attributes: A dictionary of attributes to attach to the task span.

    Returns:
        A TaskSpan object.
    """
    if (run := current_run_span.get()) is None:
        raise RuntimeError("Task spans must be created within a run")

    label = label or clean_str(name)
    return TaskSpan(
        name=name,
        label=label,
        attributes=attributes,
        params=params,
        tags=tags,
        run_id=run.run_id,
        tracer=self._get_tracer(),
    )
```


</Accordion>