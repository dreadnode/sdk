---
title: dreadnode.artifact
---

{/*
::: dreadnode.artifact.merger
::: dreadnode.artifact.storage
::: dreadnode.artifact.tree_builder
*/}

Utility for merging artifact tree structures while preserving directory hierarchy.

ArtifactMerger
--------------

```python
ArtifactMerger()
```

Class responsible for merging artifact tree structures.
Handles overlapping directory structures and efficiently combines artifacts.

Example

```python
# Create a merger instance
merger = ArtifactMerger()

# Add multiple artifact trees
merger.add_tree(tree1)  # First tree gets added directly
merger.add_tree(tree2)  # Second tree gets merged if it overlaps

# Get the merged result
merged_trees = merger.get_merged_trees()
```


<Accordion title="Source code in dreadnode/artifact/merger.py" icon="code">
```python
def __init__(self) -> None:
    self._path_map: dict[str, DirectoryNode | FileNode] = {}
    # Maps file hashes to all matching files
    self._hash_map: dict[str, list[FileNode]] = {}
    self._merged_trees: list[DirectoryNode] = []
```


</Accordion>

### add\_tree

```python
add_tree(new_tree: DirectoryNode) -> None
```

Add a new artifact tree, merging with existing trees if needed.

This method analyzes the new tree and determines how to integrate it
with existing trees, handling parent/child relationships and overlaps.

**Parameters:**

* **`new_tree`**
  (`DirectoryNode`)
  –New directory tree to add

Example

```python
# Add first tree (e.g., /data/audio/sub1)
merger.add_tree({
    "type": "dir",
    "dir_path": "/data/audio/sub1",
    "hash": "abc123",
    "children": [...]
})

# Add parent directory later (e.g., /data/audio)
# The merger will recognize the relationship and restructure
merger.add_tree({
    "type": "dir",
    "dir_path": "/data/audio",
    "hash": "def456",
    "children": [...]
})
```


<Accordion title="Source code in dreadnode/artifact/merger.py" icon="code">
```python
def add_tree(self, new_tree: DirectoryNode) -> None:
    """
    Add a new artifact tree, merging with existing trees if needed.

    This method analyzes the new tree and determines how to integrate it
    with existing trees, handling parent/child relationships and overlaps.

    Args:
        new_tree: New directory tree to add

    Example:
        ~~~python
        # Add first tree (e.g., /data/audio/sub1)
        merger.add_tree({
            "type": "dir",
            "dir_path": "/data/audio/sub1",
            "hash": "abc123",
            "children": [...]
        })

        # Add parent directory later (e.g., /data/audio)
        # The merger will recognize the relationship and restructure
        merger.add_tree({
            "type": "dir",
            "dir_path": "/data/audio",
            "hash": "def456",
            "children": [...]
        })
        ~~~
    """
    # First artifact - just add it
    if not self._merged_trees:
        self._merged_trees = [new_tree]
        self._build_maps(new_tree)
        return

    # Get new tree's path
    new_dir_path = new_tree["dir_path"]

    # Check for direct match with existing trees
    for existing_tree in self._merged_trees:
        if existing_tree["dir_path"] == new_dir_path:
            # Same directory - merge them
            self._merge_directory_nodes(existing_tree, new_tree)
            self._build_maps()  # Rebuild maps
            return

    # Check if new tree is parent of any existing trees
    children_to_remove = []
    for existing_tree in self._merged_trees:
        existing_dir_path = existing_tree["dir_path"]

        # New tree is parent of existing tree
        if existing_dir_path.startswith(new_dir_path + "/"):
            rel_path = existing_dir_path[len(new_dir_path) + 1 :].split("/")
            self._place_tree_at_path(new_tree, existing_tree, rel_path)
            children_to_remove.append(existing_tree)

    # Remove trees that are now incorporated into new tree
    if children_to_remove:
        for child in children_to_remove:
            if child in self._merged_trees:
                self._merged_trees.remove(child)
        self._merged_trees.append(new_tree)
        self._build_maps()  # Rebuild maps
        return

    # Check if new tree is child of an existing tree
    for existing_tree in self._merged_trees:
        existing_dir_path = existing_tree["dir_path"]

        if new_dir_path.startswith(existing_dir_path + "/"):
            rel_path = new_dir_path[len(existing_dir_path) + 1 :].split("/")
            self._place_tree_at_path(existing_tree, new_tree, rel_path)
            self._build_maps()  # Rebuild maps
            return

    # Try to find and handle overlaps
    new_path_map: dict[str, DirectoryNode | FileNode] = {}
    new_hash_map: dict[str, list[FileNode]] = {}
    self._build_path_and_hash_maps(new_tree, new_path_map, new_hash_map)

    # Find common paths between existing and new tree
    path_overlaps = set(self._path_map.keys()) & set(new_path_map.keys())

    if path_overlaps and self._handle_overlaps(path_overlaps, new_path_map):
        # Successfully merged via overlaps
        self._build_maps()  # Rebuild maps
        return

    # If we get here, add new tree as a separate root
    self._merged_trees.append(new_tree)
    self._build_maps()  # Rebuild maps
```


</Accordion>

### get\_merged\_trees

```python
get_merged_trees() -> list[DirectoryNode]
```

Get the current merged trees.

**Returns:**

* `list[DirectoryNode]`
  –List of merged directory trees

Example

```python
# Get the merged trees after adding multiple trees
trees = merger.get_merged_trees()

# Typically there will be a single root tree if all added trees are related
if len(trees) == 1:
    root_tree = trees[0]
    print(f"Root directory: {root_tree['dir_path']}")
```


<Accordion title="Source code in dreadnode/artifact/merger.py" icon="code">
```python
def get_merged_trees(self) -> list[DirectoryNode]:
    """
    Get the current merged trees.

    Returns:
        List of merged directory trees

    Example:
        ~~~python
        # Get the merged trees after adding multiple trees
        trees = merger.get_merged_trees()

        # Typically there will be a single root tree if all added trees are related
        if len(trees) == 1:
            root_tree = trees[0]
            print(f"Root directory: {root_tree['dir_path']}")
        ~~~
    """
    return self._merged_trees
```


</Accordion>
Artifact storage implementation for fsspec-compatible file systems.
Provides efficient uploading of files and directories with deduplication.

ArtifactStorage
---------------

```python
ArtifactStorage(credential_manager: CredentialManager)
```

Storage for artifacts with efficient handling of large files and directories.

Supports:
- Content-based deduplication using SHA1 hashing
- Batch uploads for directories handled by fsspec

Initialize artifact storage with credential manager.

**Parameters:**

* **`credential_manager`**
  (`CredentialManager`)
  –Optional credential manager for S3 operations

<Accordion title="Source code in dreadnode/artifact/storage.py" icon="code">
```python
def __init__(self, credential_manager: CredentialManager):
    """
    Initialize artifact storage with credential manager.

    Args:
        credential_manager: Optional credential manager for S3 operations
    """
    self._credential_manager: CredentialManager = credential_manager
```


</Accordion>

### batch\_upload\_files

```python
batch_upload_files(
    source_paths: list[str], target_paths: list[str]
) -> list[str]
```

Upload multiple files in a single batch operation.

**Parameters:**

* **`source_paths`**
  (`list[str]`)
  –List of local file paths
* **`target_paths`**
  (`list[str]`)
  –List of target keys/paths

**Returns:**

* `list[str]`
  –List of URIs for the uploaded files

<Accordion title="Source code in dreadnode/artifact/storage.py" icon="code">
```python
def batch_upload_files(self, source_paths: list[str], target_paths: list[str]) -> list[str]:
    """
    Upload multiple files in a single batch operation.

    Args:
        source_paths: List of local file paths
        target_paths: List of target keys/paths

    Returns:
        List of URIs for the uploaded files
    """
    if not source_paths:
        return []

    def batch_upload_operation() -> list[str]:
        filesystem = self._credential_manager.get_filesystem()

        srcs = []
        dsts = []

        for src, dst in zip(source_paths, target_paths, strict=False):
            if not filesystem.exists(dst):
                srcs.append(src)
                dsts.append(dst)

        if srcs:
            filesystem.put(srcs, dsts)
            logger.info("Batch upload completed for %d files", len(srcs))
        else:
            logger.info("All files already exist, skipping upload")

        return [str(filesystem.unstrip_protocol(target)) for target in target_paths]

    return self._credential_manager.execute_with_retry(batch_upload_operation)
```


</Accordion>

### compute\_file\_hash

```python
compute_file_hash(
    file_path: Path, stream_threshold_mb: int = 10
) -> str
```

Compute SHA1 hash of a file, using streaming only for larger files.

**Parameters:**

* **`file_path`**
  (`Path`)
  –Path to the file
* **`stream_threshold_mb`**
  (`int`, default:
  `10`
  )
  –Size threshold in MB for streaming vs. loading whole file

**Returns:**

* `str`
  –First 16 chars of SHA1 hash

<Accordion title="Source code in dreadnode/artifact/storage.py" icon="code">
```python
def compute_file_hash(self, file_path: Path, stream_threshold_mb: int = 10) -> str:
    """
    Compute SHA1 hash of a file, using streaming only for larger files.

    Args:
        file_path: Path to the file
        stream_threshold_mb: Size threshold in MB for streaming vs. loading whole file

    Returns:
        First 16 chars of SHA1 hash
    """

    file_size = file_path.stat().st_size
    stream_threshold = stream_threshold_mb * 1024 * 1024

    sha1 = hashlib.sha1()  # noqa: S324 # nosec

    if file_size < stream_threshold:
        with file_path.open("rb") as f:
            data = f.read()
            sha1.update(data)
    else:
        with file_path.open("rb") as f:
            for chunk in iter(lambda: f.read(CHUNK_SIZE), b""):
                sha1.update(chunk)

    return sha1.hexdigest()[:16]
```


</Accordion>

### compute\_file\_hashes

```python
compute_file_hashes(
    file_paths: list[Path],
) -> dict[str, str]
```

Compute SHA1 hashes for multiple files.

**Parameters:**

* **`file_paths`**
  (`list[Path]`)
  –List of file paths to hash

**Returns:**

* `dict[str, str]`
  –Dictionary mapping file paths to their hash values

<Accordion title="Source code in dreadnode/artifact/storage.py" icon="code">
```python
def compute_file_hashes(self, file_paths: list[Path]) -> dict[str, str]:
    """
    Compute SHA1 hashes for multiple files.

    Args:
        file_paths: List of file paths to hash

    Returns:
        Dictionary mapping file paths to their hash values
    """
    result = {}
    for file_path in file_paths:
        file_path_str = file_path.resolve().as_posix()
        result[file_path_str] = self.compute_file_hash(file_path)
    return result
```


</Accordion>

### store\_file

```python
store_file(file_path: Path, target_key: str) -> str
```

Store a file in the storage system, using multipart upload for large files.

**Parameters:**

* **`file_path`**
  (`Path`)
  –Path to the local file
* **`target_key`**
  (`str`)
  –Key/path where the file should be stored

**Returns:**

* `str`
  –Full URI with protocol to the stored file

<Accordion title="Source code in dreadnode/artifact/storage.py" icon="code">
```python
def store_file(self, file_path: Path, target_key: str) -> str:
    """
    Store a file in the storage system, using multipart upload for large files.

    Args:
        file_path: Path to the local file
        target_key: Key/path where the file should be stored

    Returns:
        Full URI with protocol to the stored file
    """

    def store_operation() -> str:
        filesystem = self._credential_manager.get_filesystem()

        if not filesystem.exists(target_key):
            filesystem.put(str(file_path), target_key)
            logger.info("Artifact successfully stored at %s", target_key)
        else:
            logger.info("Artifact already exists at %s, skipping upload.", target_key)

        return str(filesystem.unstrip_protocol(target_key))

    return self._credential_manager.execute_with_retry(store_operation)
```


</Accordion>
Tree structure builder for artifacts with directory hierarchy preservation.
Provides efficient uploads and tree construction for frontend to consume.

ArtifactTreeBuilder
-------------------

```python
ArtifactTreeBuilder(
    storage: ArtifactStorage, prefix_path: str | None = None
)
```

Builds a hierarchical tree structure for artifacts while uploading them to storage.
Preserves directory structure and handles efficient uploads.

### process\_artifact

```python
process_artifact(local_uri: str | Path) -> DirectoryNode
```

Process an artifact (file or directory) and build its tree representation.

**Parameters:**

* **`local_uri`**
  (`str | Path`)
  –Path to the local file or directory

**Returns:**

* `DirectoryNode`
  –Directory tree structure representing the artifact

**Raises:**

* `FileNotFoundError`
  –If the path doesn't exist

<Accordion title="Source code in dreadnode/artifact/tree_builder.py" icon="code">
```python
def process_artifact(self, local_uri: str | Path) -> DirectoryNode:
    """
    Process an artifact (file or directory) and build its tree representation.

    Args:
        local_uri: Path to the local file or directory

    Returns:
        Directory tree structure representing the artifact

    Raises:
        FileNotFoundError: If the path doesn't exist
    """
    local_path = Path(local_uri).expanduser().resolve()
    if not local_path.exists():
        raise FileNotFoundError(f"{local_path} does not exist")

    if local_path.is_dir():
        return self._process_directory(local_path)

    return self._process_single_file(local_path)
```


</Accordion>

DirectoryNode
-------------

Represents a directory node in the artifact tree.
Contains metadata about the directory, including its dir\_path, hash, and children nodes.

FileNode
--------

Represents a file node in the artifact tree.
Contains metadata about the file, including its name, uri, size\_bytes, and final\_real\_path.